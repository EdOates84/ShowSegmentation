{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(frame1, frame2):\n",
    "    #s = measure.compare_mse(frame1, frame2)\n",
    "    s = measure.compare_ssim(frame1, frame2, multichannel=True)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundaries(vid_path):\n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"FPS of the video: {}\".formatfps)\n",
    "    vidcap.set\n",
    "    success, frame1 = vidcap.read()\n",
    "    sims = []\n",
    "    count = 0\n",
    "    while success:\n",
    "        success, frame2 = vidcap.read()\n",
    "        if success:\n",
    "            sim = similarity(frame1, frame2)\n",
    "            sims.append(sim)\n",
    "            print(\"At frame {}: similarity = {}\".format(count, sim))\n",
    "            frame1 = frame2\n",
    "            count += 1\n",
    "    #Plotting time vs similarities\n",
    "    plt.plot([x/fps for x in range(count)], sims)\n",
    "    plt.show()\n",
    "    return sims, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sims,_ = find_boundaries(\"../data/SAA_clip.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sims_inv = [1-x for x in sims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x/fps for x in range(len(sims))], sims_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sims_inv)):\n",
    "    if(sims_inv[i]==max(sims_inv)):\n",
    "        print(i/fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySceneDetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_milsec(timestr):\n",
    "    HMS,MSEC = timestr.split('.')\n",
    "    x = time.strptime(HMS,'%H:%M:%S')\n",
    "    seconds = datetime.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
    "    return seconds*1000 + int(MSEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_boundaries(vid_path):\n",
    "    command = \"scenedetect -i {} -s video.stats.csv detect-content list-scenes\".format(vid_path)\n",
    "    os.system(command)\n",
    "    file_name = os.path.basename(vid_path).split('.')[0]\n",
    "    results = pd.read_csv(\"{}-Scenes.csv\".format(file_name))\n",
    "    results = results.columns.tolist()[1:] #List of timestamps of shot boundaries\n",
    "    shot_bounds = [time_to_milsec(x) for x in results]\n",
    "    return shot_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_frames(shot_bounds, vid_path):\n",
    "    # Taking centre frame of each shot - creating a list of such \n",
    "    # centre frames from the extracted shot boundaries\n",
    "    key_frames = []\n",
    "    timestamps = []\n",
    "    bound1 = 0\n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    for i in tqdm(range(len(shot_bounds) + 1)):\n",
    "        \n",
    "        if(i != len(shot_bounds)): #not last boundary\n",
    "            bound2 = shot_bounds[i]\n",
    "            \n",
    "        else: #last boundary\n",
    "            vidcap.set(cv2.CAP_PROP_POS_AVI_RATIO,1)\n",
    "            bound2 = vidcap.get(cv2.CAP_PROP_POS_MSEC) #max duration\n",
    "            \n",
    "        key_frame_msec = (bound1 + bound2)/2 #Average of 2 boundaries\n",
    "        timestamps.append(key_frame_msec)\n",
    "        #print(key_frame_msec)\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,key_frame_msec)\n",
    "        _,image = vidcap.read() #Reading frame at key_frame_sec\n",
    "        key_frames.append(image) #storing frame as np array\n",
    "        bound1 = bound2\n",
    "        \n",
    "    return key_frames,timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scenes(vid_path, threshold):\n",
    "    print('Finding shot boundaries...')\n",
    "    shot_bounds = shot_boundaries(vid_path)\n",
    "    print('Extracting key frames...')\n",
    "    key_frames, kf_timestamps = get_key_frames(shot_bounds,vid_path)\n",
    "    #print(key_frames)\n",
    "    scene_count = 0\n",
    "    scenes = [0] #What scene is each shot - length = no. of shots [Maps shots to scenes]\n",
    "    key_shots = [0] #Key shot for each scene [Maps scenes to their key shots]\n",
    "    print('Classifying shots into scenes...')\n",
    "    for i in tqdm(range(1, len(key_frames))): #For each shot\n",
    "        curr_shot = key_frames[i]\n",
    "        for j,key_shot in enumerate(key_shots[-15:]): #Iterate through each scene\n",
    "            if(similarity(key_frames[key_shot],curr_shot) > threshold):\n",
    "                scenes.append(j) #Mark the shot as belonging to this scene\n",
    "                break\n",
    "            elif(j==len(key_shots)-1): #End of scenes => No matching scene is found\n",
    "                scene_count += 1 \n",
    "                scenes.append(scene_count) #This shot belongs to the new scene\n",
    "                key_shots.append(i) #Mark this shot as key shot of the new scene\n",
    "    return (scenes, key_shots, scene_count, key_frames, kf_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding shot boundaries...\n"
     ]
    }
   ],
   "source": [
    "output = find_scenes(\"../../2006-01-02_0000_US_00001057_V11_M2_VHS10_H4_JA.mp4\", 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

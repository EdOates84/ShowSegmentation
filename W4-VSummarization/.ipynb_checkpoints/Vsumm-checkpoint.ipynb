{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "import face_recognition\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot Boundary Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_milsec(timestr):\n",
    "    \"\"\"Converts scenedetect's output time string into milliseconds\"\"\"\n",
    "    HMS,MSEC = timestr.split('.')\n",
    "    x = time.strptime(HMS,'%H:%M:%S')\n",
    "    seconds = datetime.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
    "    return seconds*1000 + int(MSEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_boundaries(vid_path):\n",
    "    \"\"\"Returns list of shot boundaries in video_time\"\"\"\n",
    "    file_name = os.path.basename(vid_path).split('.')[0]\n",
    "    command = \"scenedetect -i {} -s {}.stats.csv detect-content list-scenes\".format(vid_path,file_name)\n",
    "    os.system(command)\n",
    "    results = pd.read_csv(\"{}-Scenes.csv\".format(file_name))\n",
    "    results = results.columns.tolist()[1:] #List of timestamps of shot boundaries\n",
    "    shot_bounds = [time_to_milsec(x) for x in results]\n",
    "    return shot_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VASNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] cuda_device: 0\n",
      "[1] datasets: ['datasets/eccv16_dataset_summe_google_pool5.h5', 'datasets/eccv16_dataset_tvsum_google_pool5.h5', 'datasets/eccv16_dataset_ovp_google_pool5.h5', 'datasets/eccv16_dataset_youtube_google_pool5.h5']\n",
      "[2] epochs_max: 300\n",
      "[3] l2_req: 1e-05\n",
      "[4] lr: [5e-05]\n",
      "[5] lr_epochs: [0]\n",
      "[6] max_summary_length: 0.15\n",
      "[7] output_dir: ex-10\n",
      "[8] root: \n",
      "[9] splits: ['splits/tvsum_splits.json', 'splits/summe_splits.json', 'splits/tvsum_aug_splits.json', 'splits/summe_aug_splits.json']\n",
      "[10] train_batch_size: 1\n",
      "[11] use_cuda: False\n",
      "[12] verbose: False\n",
      "\n",
      "[0] cuda_device: 0\n",
      "[1] datasets: ['set1,set2,set3']\n",
      "[2] epochs_max: 300\n",
      "[3] l2_req: 1e-05\n",
      "[4] lr: [5e-05]\n",
      "[5] lr_epochs: [0]\n",
      "[6] max_summary_length: 0.15\n",
      "[7] new_param_float: 1.23456\n",
      "[8] output_dir: ex-10\n",
      "[9] root: root_dir\n",
      "[10] splits: ['split1,', 'split2']\n",
      "[11] train_batch_size: 1\n",
      "[12] use_cuda: False\n",
      "[13] verbose: False\n",
      "\n",
      "Packages & system versions:\n",
      "----------------------------------------------------------------------\n",
      "display :  \tcat: /proc/driver/nvidia/version: No such file or directory\n",
      "cuda :  NA\n",
      "cudnn :  None\n",
      "platform :  Linux-4.15.0-51-generic-x86_64-with-debian-stretch-sid\n",
      "python :  (3, 7, 3)\n",
      "torch :  1.1.0\n",
      "numpy :  1.16.4\n",
      "h5py :  2.8.0\n",
      "json :  2.0.9\n",
      "ortools :  7.1.6720\n",
      "torchvision :  0.3.0\n",
      "\n",
      "[0, 1]\n",
      "[0. 0. 1. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "__author__ = 'Jiri Fajtl'\n",
    "__email__ = 'ok1zjf@gmail.com'\n",
    "__version__= '3.6'\n",
    "__status__ = \"Research\"\n",
    "__date__ = \"1/12/2018\"\n",
    "__license__= \"MIT License\"\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "import h5py\n",
    "import json\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import platform\n",
    "import sys\n",
    "import pkg_resources\n",
    "import torch\n",
    "import h5py\n",
    "import json\n",
    "import ortools\n",
    "from torch.nn.modules.module import _addindent\n",
    "import numpy as np\n",
    "from ortools.algorithms import pywrapknapsack_solver\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__author__ = 'Jiri Fajtl'\n",
    "__email__ = 'ok1zjf@gmail.com'\n",
    "__version__= '3.6'\n",
    "__status__ = \"Research\"\n",
    "__date__ = \"1/12/2018\"\n",
    "__license__= \"MIT License\"\n",
    "\n",
    "\n",
    "\n",
    "class HParameters:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.verbose = False\n",
    "        self.use_cuda = False\n",
    "        self.cuda_device = 0\n",
    "        self.max_summary_length = 0.15\n",
    "\n",
    "        self.l2_req = 0.00001\n",
    "        self.lr_epochs = [0]\n",
    "        self.lr = [0.00005]\n",
    "\n",
    "        self.epochs_max = 300\n",
    "        self.train_batch_size = 1\n",
    "\n",
    "        self.output_dir = 'ex-10'\n",
    "\n",
    "        self.root = ''\n",
    "        self.datasets=['datasets/eccv16_dataset_summe_google_pool5.h5',\n",
    "                       'datasets/eccv16_dataset_tvsum_google_pool5.h5',\n",
    "                       'datasets/eccv16_dataset_ovp_google_pool5.h5',\n",
    "                       'datasets/eccv16_dataset_youtube_google_pool5.h5']\n",
    "\n",
    "        self.splits = ['splits/tvsum_splits.json',\n",
    "                        'splits/summe_splits.json']\n",
    "\n",
    "        self.splits += ['splits/tvsum_aug_splits.json',\n",
    "                        'splits/summe_aug_splits.json']\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def get_dataset_by_name(self, dataset_name):\n",
    "        for d in self.datasets:\n",
    "            if dataset_name in d:\n",
    "                return [d]\n",
    "        return None\n",
    "\n",
    "    def load_from_args(self, args):\n",
    "        for key in args:\n",
    "            val = args[key]\n",
    "            if val is not None:\n",
    "                if hasattr(self, key) and isinstance(getattr(self, key), list):\n",
    "                    val = val.split()\n",
    "\n",
    "                setattr(self, key, val)\n",
    "\n",
    "    def __str__(self):\n",
    "        vars = [attr for attr in dir(self) if not callable(getattr(self,attr)) and not (attr.startswith(\"__\") or attr.startswith(\"_\"))]\n",
    "\n",
    "        info_str = ''\n",
    "        for i, var in enumerate(vars):\n",
    "            val = getattr(self, var)\n",
    "            if isinstance(val, Variable):\n",
    "                val = val.data.cpu().numpy().tolist()[0]\n",
    "            info_str += '['+str(i)+'] '+var+': '+str(val)+'\\n'\n",
    "\n",
    "        return info_str\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Tests\n",
    "    hps = HParameters()\n",
    "    print(hps)\n",
    "\n",
    "    args = {'root': 'root_dir',\n",
    "            'datasets': 'set1,set2,set3',\n",
    "            'splits': 'split1, split2',\n",
    "            'new_param_float': 1.23456\n",
    "            }\n",
    "\n",
    "    hps.load_from_args(args)\n",
    "    print(hps)\n",
    "\n",
    "__author__ = 'Jiri Fajtl'\n",
    "__email__ = 'ok1zjf@gmail.com'\n",
    "__version__= '3.6'\n",
    "__status__ = \"Research\"\n",
    "__date__ = \"1/12/2018\"\n",
    "__license__= \"MIT License\"\n",
    "\n",
    "\n",
    "\n",
    "# import PIL as Image\n",
    "# import cv2\n",
    "\n",
    "def list_files(path, extensions=[], sort=True, max_len=-1):\n",
    "    if os.path.isdir(path):\n",
    "        filenames = [os.path.join(path, fn) for fn in os.listdir(path) if\n",
    "                           any([fn.lower().endswith(ext) for ext in extensions])]\n",
    "    else:\n",
    "        print(\"ERROR. \", path,' is not a directory!')\n",
    "        return []\n",
    "\n",
    "    if sort:\n",
    "        filenames.sort()\n",
    "\n",
    "    if max_len>-1:\n",
    "        filenames = filenames[:max_len]\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def del_file(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "def get_video_list(video_path, max_len=-1, extensions=['avi', 'flv', 'mpg', 'mp4']):\n",
    "    return list_files(video_path, extensions=extensions , sort=True, max_len=max_len)\n",
    "\n",
    "def get_image_list(video_path, max_len=-1):\n",
    "    return list_files(video_path, extensions=['jpg', 'jpeg', 'png'], sort=True, max_len=max_len)\n",
    "\n",
    "def run_command(command):\n",
    "    p = subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    return '\\n'.join([ '\\t'+line.decode(\"utf-8\").strip() for line in p.stdout.readlines()])\n",
    "\n",
    "def ge_pkg_versions():\n",
    "    dep_versions = {}\n",
    "    dep_versions['display'] = run_command('cat /proc/driver/nvidia/version')\n",
    "\n",
    "    dep_versions['cuda'] = 'NA'\n",
    "    cuda_home = '/usr/local/cuda/'\n",
    "    if 'CUDA_HOME' in os.environ:\n",
    "        cuda_home = os.environ['CUDA_HOME']\n",
    "\n",
    "    cmd = cuda_home+'/version.txt'\n",
    "    if os.path.isfile(cmd):\n",
    "        dep_versions['cuda'] = run_command('cat '+cmd)\n",
    "\n",
    "    dep_versions['cudnn'] = torch.backends.cudnn.version()\n",
    "    dep_versions['platform'] = platform.platform()\n",
    "    dep_versions['python'] = sys.version_info[:3]\n",
    "    dep_versions['torch'] = torch.__version__\n",
    "    dep_versions['numpy'] = np.__version__\n",
    "    dep_versions['h5py'] = h5py.__version__\n",
    "    dep_versions['json'] = json.__version__\n",
    "    dep_versions['ortools'] = ortools.__version__\n",
    "    dep_versions['torchvision'] = pkg_resources.get_distribution(\"torchvision\").version\n",
    "\n",
    "    # dep_versions['PIL'] = Image.VERSION\n",
    "    # dep_versions['OpenCV'] = 'NA'\n",
    "    # if 'cv2' in sys.modules:\n",
    "    #     dep_versions['OpenCV'] = cv2.__version__\n",
    "\n",
    "\n",
    "    return dep_versions\n",
    "\n",
    "\n",
    "def print_pkg_versions():\n",
    "    print(\"Packages & system versions:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    versions = ge_pkg_versions()\n",
    "    for key, val in versions.items():\n",
    "        print(key,\": \",val)\n",
    "    print(\"\")\n",
    "    return\n",
    "\n",
    "\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
    "    parameters = 0\n",
    "    convs = 0\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [torch.nn.modules.container.Container, torch.nn.modules.container.Sequential]:\n",
    "            modstr, p, cnvs = torch_summarize(module)\n",
    "            parameters += p\n",
    "            convs += cnvs\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "            convs += len(modstr.split('Conv2d')) - 1\n",
    "\n",
    "        modstr = _addindent(modstr, 2)\n",
    "        # if 'conv' in key:\n",
    "        #     convs += 1\n",
    "\n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
    "        parameters += params\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "\n",
    "        tmpstr += '  (' + key + '): ' + modstr\n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr += ', parameters={} / {}'.format(params, parameters)\n",
    "        tmpstr += ', convs={}'.format(convs)\n",
    "        tmpstr += '\\n'\n",
    "\n",
    "    tmpstr = tmpstr + ')'\n",
    "    return tmpstr, parameters, convs\n",
    "\n",
    "\n",
    "def print_table(table, cell_width=[3,35,8]):\n",
    "    slen=sum(cell_width)+len(cell_width)*2+2\n",
    "    print('-'*slen)\n",
    "    header = table.pop(0)\n",
    "    for i, head in enumerate(header):\n",
    "        print('  {name: <{alignment}}'.format(name=head, alignment=cell_width[i]), end='')\n",
    "\n",
    "    print('')\n",
    "    print('='*slen)\n",
    "    for row in table:\n",
    "        for i, val in enumerate(row):\n",
    "            print('  {val: <{alignment}}'.format(val=val, alignment=cell_width[i]), end='')\n",
    "        print('')\n",
    "    print('-'*slen)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Tests\n",
    "    print_pkg_versions()\n",
    "\n",
    "''''\n",
    "Courtesy of KaiyangZhou\n",
    "https://github.com/KaiyangZhou/pytorch-vsumm-reinforce\n",
    "\n",
    "@article{zhou2017reinforcevsumm,\n",
    "   title={Deep Reinforcement Learning for Unsupervised Video Summarization with Diversity-Representativeness Reward},\n",
    "   author={Zhou, Kaiyang and Qiao, Yu and Xiang, Tao},\n",
    "   journal={arXiv:1801.00054},\n",
    "   year={2017}\n",
    "}\n",
    "\n",
    "Modifications by Jiri Fajtl\n",
    "- knapsack replaced with knapsack_ortools\n",
    "- added evaluate_user_summaries() for user summaries ground truth evaluation\n",
    "'''\n",
    "\n",
    "\n",
    "#from knapsack import knapsack_dp\n",
    "# A Dynamic Programming based Python Program for 0-1 Knapsack problem\n",
    "# Returns the maximum value that can be put in a knapsack of capacity W\n",
    "\n",
    "\n",
    "\n",
    "def knapsack(W, wt, val, n):\n",
    "    K = [[0 for x in range(W+1)] for x in range(n+1)]\n",
    "\n",
    "    # Build table K[][] in bottom up manner\n",
    "    for i in range(n+1):\n",
    "        for w in range(W+1):\n",
    "            if i==0 or w==0:\n",
    "                K[i][w] = 0\n",
    "            elif wt[i-1] <= w:\n",
    "                K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]],  K[i-1][w])\n",
    "            else:\n",
    "                K[i][w] = K[i-1][w]\n",
    "\n",
    "\n",
    "    best = K[n][W]\n",
    "\n",
    "    amount = np.zeros(n)\n",
    "    a = best\n",
    "    j = n\n",
    "    Y = W\n",
    "\n",
    "    # j = j + 1;\n",
    "    #\n",
    "    # amount(j) = 1;\n",
    "    # Y = Y - weights(j);\n",
    "    # j = j - 1;\n",
    "    # a = A(j + 1, Y + 1);\n",
    "\n",
    "    while a > 0:\n",
    "       while K[j][Y] == a:\n",
    "           j = j - 1\n",
    "\n",
    "       j = j + 1\n",
    "       amount[j-1] = 1\n",
    "       Y = Y - wt[j-1]\n",
    "       j = j - 1\n",
    "       a = K[j][Y]\n",
    "\n",
    "    return amount\n",
    "\n",
    "\n",
    "def test_knapsack():\n",
    "    weights = [1 ,1 ,1, 1 ,2 ,2 ,3]\n",
    "    values  = [1 ,1 ,2 ,3, 1, 3 ,5]\n",
    "    best = 13\n",
    "    print(knapsack(7, weights, values, 7))\n",
    "\n",
    "#===========================================\n",
    "'''\n",
    "------------------------------------------------\n",
    "Use dynamic programming (DP) to solve 0/1 knapsack problem\n",
    "Time complexity: O(nW), where n is number of items and W is capacity\n",
    "\n",
    "Author: Kaiyang Zhou\n",
    "Website: https://kaiyangzhou.github.io/\n",
    "------------------------------------------------\n",
    "knapsack_dp(values,weights,n_items,capacity,return_all=False)\n",
    "\n",
    "Input arguments:\n",
    "  1. values: a list of numbers in either int or float, specifying the values of items\n",
    "  2. weights: a list of int numbers specifying weights of items\n",
    "  3. n_items: an int number indicating number of items\n",
    "  4. capacity: an int number indicating the knapsack capacity\n",
    "  5. return_all: whether return all info, defaulty is False (optional)\n",
    "\n",
    "Return:\n",
    "  1. picks: a list of numbers storing the positions of selected items\n",
    "  2. max_val: maximum value (optional)\n",
    "------------------------------------------------\n",
    "'''\n",
    "def knapsack_dp(values,weights,n_items,capacity,return_all=False):\n",
    "    check_inputs(values,weights,n_items,capacity)\n",
    "\n",
    "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "\n",
    "    for i in range(1,n_items+1):\n",
    "        for w in range(0,capacity+1):\n",
    "            wi = weights[i-1] # weight of current item\n",
    "            vi = values[i-1] # value of current item\n",
    "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
    "                table[i,w] = vi + table[i-1,w-wi]\n",
    "                keep[i,w] = 1\n",
    "            else:\n",
    "                table[i,w] = table[i-1,w]\n",
    "\n",
    "    picks = []\n",
    "    K = capacity\n",
    "\n",
    "    for i in range(n_items,0,-1):\n",
    "        if keep[i,K] == 1:\n",
    "            picks.append(i)\n",
    "            K -= weights[i-1]\n",
    "\n",
    "    picks.sort()\n",
    "    picks = [x-1 for x in picks] # change to 0-index\n",
    "\n",
    "    if return_all:\n",
    "        max_val = table[n_items,capacity]\n",
    "        return picks,max_val\n",
    "    return picks\n",
    "\n",
    "def check_inputs(values,weights,n_items,capacity):\n",
    "    # check variable type\n",
    "    assert(isinstance(values,list))\n",
    "    assert(isinstance(weights,list))\n",
    "    assert(isinstance(n_items,int))\n",
    "    assert(isinstance(capacity,int))\n",
    "    # check value type\n",
    "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
    "    assert(all(isinstance(val,int) for val in weights))\n",
    "    # check validity of value\n",
    "    assert(all(val >= 0 for val in weights))\n",
    "    assert(n_items > 0)\n",
    "    assert(capacity > 0)\n",
    "\n",
    "def test_knapsack_dp():\n",
    "    values = [2,3,4]\n",
    "    weights = [1,2,3]\n",
    "    n_items = 3\n",
    "    capacity = 3\n",
    "    picks = knapsack_dp(values,weights,n_items,capacity)\n",
    "    print (picks)\n",
    "\n",
    "\n",
    "\n",
    "osolver = pywrapknapsack_solver.KnapsackSolver(\n",
    "    # pywrapknapsack_solver.KnapsackSolver.KNAPSACK_MULTIDIMENSION_BRANCH_AND_BOUND_SOLVER,\n",
    "    pywrapknapsack_solver.KnapsackSolver.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER,\n",
    "    'test')\n",
    "\n",
    "def knapsack_ortools(values, weights, items, capacity ):\n",
    "    scale = 1000\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    values = (values * scale).astype(np.int)\n",
    "    weights = (weights).astype(np.int)\n",
    "    capacity = capacity\n",
    "\n",
    "    osolver.Init(values.tolist(), [weights.tolist()], [capacity])\n",
    "    computed_value = osolver.Solve()\n",
    "    packed_items = [x for x in range(0, len(weights))\n",
    "                    if osolver.BestSolutionContains(x)]\n",
    "\n",
    "    return packed_items\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_knapsack_dp()\n",
    "    test_knapsack()\n",
    "\n",
    "\n",
    "\n",
    "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
    "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
    "    Args:\n",
    "    ---------------------------------------------\n",
    "    - ypred: predicted importance scores.\n",
    "    - cps: change points, 2D matrix, each row contains a segment.\n",
    "    - n_frames: original number of frames.\n",
    "    - nfps: number of frames per segment.\n",
    "    - positions: positions of subsampled frames in the original video.\n",
    "    - proportion: length of video summary (compared to original video length).\n",
    "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
    "    \"\"\"\n",
    "    n_segs = cps.shape[0]\n",
    "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
    "    if positions.dtype != int:\n",
    "        positions = positions.astype(np.int32)\n",
    "    if positions[-1] != n_frames:\n",
    "        positions = np.concatenate([positions, [n_frames]])\n",
    "    for i in range(len(positions) - 1):\n",
    "        pos_left, pos_right = positions[i], positions[i+1]\n",
    "        if i == len(ypred):\n",
    "            frame_scores[pos_left:pos_right] = 0\n",
    "        else:\n",
    "            frame_scores[pos_left:pos_right] = ypred[i]\n",
    "\n",
    "    seg_score = []\n",
    "    for seg_idx in range(n_segs):\n",
    "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
    "        scores = frame_scores[start:end]\n",
    "        seg_score.append(float(scores.mean()))\n",
    "\n",
    "    limits = int(math.floor(n_frames * proportion))\n",
    "\n",
    "    if method == 'knapsack':\n",
    "        #picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
    "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
    "    elif method == 'rank':\n",
    "        order = np.argsort(seg_score)[::-1].tolist()\n",
    "        picks = []\n",
    "        total_len = 0\n",
    "        for i in order:\n",
    "            if total_len + nfps[i] < limits:\n",
    "                picks.append(i)\n",
    "                total_len += nfps[i]\n",
    "    else:\n",
    "        raise KeyError(\"Unknown method {}\".format(method))\n",
    "\n",
    "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
    "    for seg_idx in range(n_segs):\n",
    "        nf = nfps[seg_idx]\n",
    "        if seg_idx in picks:\n",
    "            tmp = np.ones((nf), dtype=np.float32)\n",
    "        else:\n",
    "            tmp = np.zeros((nf), dtype=np.float32)\n",
    "        summary = np.concatenate((summary, tmp))\n",
    "\n",
    "    summary = np.delete(summary, 0) # delete the first element\n",
    "    return summary\n",
    "\n",
    "\n",
    "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
    "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
    "    Args:\n",
    "    --------------------------------\n",
    "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
    "    eval_metric = {'avg', 'max'}\n",
    "    'avg' averages results of comparing multiple human summaries.\n",
    "    'max' takes the maximum (best) out of multiple comparisons.\n",
    "    \"\"\"\n",
    "    machine_summary = machine_summary.astype(np.float32)\n",
    "    user_summary = user_summary.astype(np.float32)\n",
    "    n_users,n_frames = user_summary.shape\n",
    "\n",
    "    # binarization\n",
    "    machine_summary[machine_summary > 0] = 1\n",
    "    user_summary[user_summary > 0] = 1\n",
    "\n",
    "    if len(machine_summary) > n_frames:\n",
    "        machine_summary = machine_summary[:n_frames]\n",
    "    elif len(machine_summary) < n_frames:\n",
    "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
    "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
    "\n",
    "    f_scores = []\n",
    "    prec_arr = []\n",
    "    rec_arr = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        gt_summary = user_summary[user_idx,:]\n",
    "        overlap_duration = (machine_summary * gt_summary).sum()\n",
    "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
    "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "        if precision == 0 and recall == 0:\n",
    "            f_score = 0.\n",
    "        else:\n",
    "            f_score = (2 * precision * recall) / (precision + recall)\n",
    "        f_scores.append(f_score)\n",
    "        prec_arr.append(precision)\n",
    "        rec_arr.append(recall)\n",
    "\n",
    "    if eval_metric == 'avg':\n",
    "        final_f_score = np.mean(f_scores)\n",
    "        final_prec = np.mean(prec_arr)\n",
    "        final_rec = np.mean(rec_arr)\n",
    "    elif eval_metric == 'max':\n",
    "        final_f_score = np.max(f_scores)\n",
    "        max_idx = np.argmax(f_scores)\n",
    "        final_prec = prec_arr[max_idx]\n",
    "        final_rec = rec_arr[max_idx]\n",
    "    \n",
    "    return final_f_score, final_prec, final_rec\n",
    "\n",
    "\n",
    "def evaluate_user_summaries(user_summary, eval_metric='avg'):\n",
    "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
    "    Args:\n",
    "    --------------------------------\n",
    "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
    "    eval_metric = {'avg', 'max'}\n",
    "    'avg' averages results of comparing multiple human summaries.\n",
    "    'max' takes the maximum (best) out of multiple comparisons.\n",
    "    \"\"\"\n",
    "    user_summary = user_summary.astype(np.float32)\n",
    "    n_users, n_frames = user_summary.shape\n",
    "\n",
    "    # binarization\n",
    "    user_summary[user_summary > 0] = 1\n",
    "\n",
    "    f_scores = []\n",
    "    prec_arr = []\n",
    "    rec_arr = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        gt_summary = user_summary[user_idx, :]\n",
    "        for other_user_idx in range(user_idx+1, n_users):\n",
    "            other_gt_summary = user_summary[other_user_idx, :]\n",
    "            overlap_duration = (other_gt_summary * gt_summary).sum()\n",
    "            precision = overlap_duration / (other_gt_summary.sum() + 1e-8)\n",
    "            recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "            if precision == 0 and recall == 0:\n",
    "                f_score = 0.\n",
    "            else:\n",
    "                f_score = (2 * precision * recall) / (precision + recall)\n",
    "            f_scores.append(f_score)\n",
    "            prec_arr.append(precision)\n",
    "            rec_arr.append(recall)\n",
    "\n",
    "\n",
    "    if eval_metric == 'avg':\n",
    "        final_f_score = np.mean(f_scores)\n",
    "        final_prec = np.mean(prec_arr)\n",
    "        final_rec = np.mean(rec_arr)\n",
    "    elif eval_metric == 'max':\n",
    "        final_f_score = np.max(f_scores)\n",
    "        max_idx = np.argmax(f_scores)\n",
    "        final_prec = prec_arr[max_idx]\n",
    "        final_rec = rec_arr[max_idx]\n",
    "\n",
    "    return final_f_score, final_prec, final_rec\n",
    "\n",
    "__author__ = 'Jiri Fajtl'\n",
    "__email__ = 'ok1zjf@gmail.com'\n",
    "__version__= '3.6'\n",
    "__status__ = \"Research\"\n",
    "__date__ = \"1/12/2018\"\n",
    "__license__= \"MIT License\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Courtesy of jekbradbury\n",
    "# https://github.com/pytorch/pytorch/issues/1959\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, apperture=-1, ignore_itself=False, input_size=1024, output_size=1024):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.apperture = apperture\n",
    "        self.ignore_itself = ignore_itself\n",
    "\n",
    "        self.m = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.K = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
    "        self.Q = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
    "        self.V = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
    "        self.output_linear = nn.Linear(in_features=self.output_size, out_features=self.m, bias=False)\n",
    "\n",
    "        self.drop50 = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]  # sequence length\n",
    "\n",
    "        K = self.K(x)  # ENC (n x m) => (n x H) H= hidden size\n",
    "        Q = self.Q(x)  # ENC (n x m) => (n x H) H= hidden size\n",
    "        V = self.V(x)\n",
    "\n",
    "        Q *= 0.06\n",
    "        logits = torch.matmul(Q, K.transpose(1,0))\n",
    "\n",
    "        if self.ignore_itself:\n",
    "            # Zero the diagonal activations (a distance of each frame with itself)\n",
    "            logits[torch.eye(n).byte()] = -float(\"Inf\")\n",
    "\n",
    "        if self.apperture > 0:\n",
    "            # Set attention to zero to frames further than +/- apperture from the current one\n",
    "            onesmask = torch.ones(n, n)\n",
    "            trimask = torch.tril(onesmask, -self.apperture) + torch.triu(onesmask, self.apperture)\n",
    "            logits[trimask == 1] = -float(\"Inf\")\n",
    "\n",
    "        att_weights_ = nn.functional.softmax(logits, dim=-1)\n",
    "        weights = self.drop50(att_weights_)\n",
    "        y = torch.matmul(V.transpose(1,0), weights).transpose(1,0)\n",
    "        y = self.output_linear(y)\n",
    "\n",
    "        return y, att_weights_\n",
    "\n",
    "\n",
    "\n",
    "class VASNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VASNet, self).__init__()\n",
    "\n",
    "        self.m = 1024 # cnn features size\n",
    "        self.hidden_size = 1024\n",
    "\n",
    "        self.att = SelfAttention(input_size=self.m, output_size=self.m)\n",
    "        self.ka = nn.Linear(in_features=self.m, out_features=1024)\n",
    "        self.kb = nn.Linear(in_features=self.ka.out_features, out_features=1024)\n",
    "        self.kc = nn.Linear(in_features=self.kb.out_features, out_features=1024)\n",
    "        self.kd = nn.Linear(in_features=self.ka.out_features, out_features=1)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop50 = nn.Dropout(0.5)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer_norm_y = LayerNorm(self.m)\n",
    "        self.layer_norm_ka = LayerNorm(self.ka.out_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        m = x.shape[2] # Feature size\n",
    "\n",
    "        # Place the video frames to the batch dimension to allow for batch arithm. operations.\n",
    "        # Assumes input batch size = 1.\n",
    "        x = x.view(-1, m)\n",
    "        y, att_weights_ = self.att(x)\n",
    "\n",
    "        y = y + x\n",
    "        y = self.drop50(y)\n",
    "        y = self.layer_norm_y(y)\n",
    "\n",
    "        # Frame level importance score regression\n",
    "        # Two layer NN\n",
    "        y = self.ka(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.drop50(y)\n",
    "        y = self.layer_norm_ka(y)\n",
    "\n",
    "        y = self.kd(y)\n",
    "        y = self.sig(y)\n",
    "        y = y.view(1, -1)\n",
    "\n",
    "        return y, att_weights_\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname == 'Linear':\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.1)\n",
    "\n",
    "def parse_splits_filename(splits_filename):\n",
    "    # Parse split file and count number of k_folds\n",
    "    spath, sfname = os.path.split(splits_filename)\n",
    "    sfname, _ = os.path.splitext(sfname)\n",
    "    dataset_name = sfname.split('_')[0]  # Get dataset name e.g. tvsum\n",
    "    dataset_type = sfname.split('_')[1]  # augmentation type e.g. aug\n",
    "\n",
    "    # The keyword 'splits' is used as the filename fields terminator from historical reasons.\n",
    "    if dataset_type == 'splits':\n",
    "        # Split type is not present\n",
    "        dataset_type = ''\n",
    "\n",
    "    # Get number of discrete splits within each split json file\n",
    "    with open(splits_filename, 'r') as sf:\n",
    "        splits = json.load(sf)\n",
    "\n",
    "    return dataset_name, dataset_type, splits\n",
    "\n",
    "def lookup_weights_splits_file(path, dataset_name, dataset_type, split_id):\n",
    "    dataset_type_str = '' if dataset_type == '' else dataset_type + '_'\n",
    "    weights_filename = path + '/models/{}_{}splits_{}_*.tar.pth'.format(dataset_name, dataset_type_str, split_id)\n",
    "    weights_filename = glob.glob(weights_filename)\n",
    "    if len(weights_filename) == 0:\n",
    "        print(\"Couldn't find model weights: \", weights_filename)\n",
    "        return ''\n",
    "\n",
    "    # Get the first weights file in the dir\n",
    "    weights_filename = weights_filename[0]\n",
    "    splits_file = path + '/splits/{}_{}splits.json'.format(dataset_name, dataset_type_str)\n",
    "\n",
    "    return weights_filename, splits_file\n",
    "\n",
    "\n",
    "class AONet:\n",
    "\n",
    "    def __init__(self, hps: HParameters):\n",
    "        self.hps = hps\n",
    "        self.model = None\n",
    "        self.log_file = None\n",
    "        self.verbose = hps.verbose\n",
    "\n",
    "\n",
    "    def fix_keys(self, keys, dataset_name = None):\n",
    "        \"\"\"\n",
    "        :param keys:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # dataset_name = None\n",
    "        if len(self.datasets) == 1:\n",
    "            dataset_name = next(iter(self.datasets))\n",
    "\n",
    "        keys_out = []\n",
    "        for key in keys:\n",
    "            t = key.split('/')\n",
    "            if len(t) != 2:\n",
    "                assert dataset_name is not None, \"ERROR dataset name in some keys is missing but there are multiple dataset {} to choose from\".format(len(self.datasets))\n",
    "\n",
    "                key_name = dataset_name+'/'+key\n",
    "                keys_out.append(key_name)\n",
    "            else:\n",
    "                keys_out.append(key)\n",
    "\n",
    "        return keys_out\n",
    "\n",
    "\n",
    "    def load_datasets(self, datasets = None):\n",
    "        \"\"\"\n",
    "        Loads all h5 datasets from the datasets list into a dictionary self.dataset\n",
    "        referenced by their base filename\n",
    "        :param datasets:  List of dataset filenames\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if datasets is None:\n",
    "            datasets = self.hps.datasets\n",
    "\n",
    "        datasets_dict = {}\n",
    "        for dataset in datasets:\n",
    "            _, base_filename = os.path.split(dataset)\n",
    "            base_filename, _ = os.path.splitext(base_filename)\n",
    "            print(\"Loading:\", dataset)\n",
    "            # dataset_name = base_filename.split('_')[2]\n",
    "            # print(\"\\tDataset name:\", dataset_name)\n",
    "            datasets_dict[base_filename] = h5py.File(dataset, 'r')\n",
    "\n",
    "        self.datasets = datasets_dict\n",
    "        return datasets_dict\n",
    "\n",
    "\n",
    "    def load_split_file(self, splits_file):\n",
    "\n",
    "        self.dataset_name, self.dataset_type, self.splits = parse_splits_filename(splits_file)\n",
    "        n_folds = len(self.splits)\n",
    "        self.split_file = splits_file\n",
    "        print(\"Loading splits from: \",splits_file)\n",
    "\n",
    "        return n_folds\n",
    "\n",
    "\n",
    "    def select_split(self, split_id):\n",
    "        print(\"Selecting split: \",split_id)\n",
    "\n",
    "        self.split_id = split_id\n",
    "        n_folds = len(self.splits)\n",
    "        assert self.split_id < n_folds, \"split_id (got {}) exceeds {}\".format(self.split_id, n_folds)\n",
    "\n",
    "        split = self.splits[self.split_id]\n",
    "        self.train_keys = split['train_keys']\n",
    "        self.test_keys = split['test_keys']\n",
    "\n",
    "        dataset_filename = self.hps.get_dataset_by_name(self.dataset_name)[0]\n",
    "        _,dataset_filename = os.path.split(dataset_filename)\n",
    "        dataset_filename,_ = os.path.splitext(dataset_filename)\n",
    "        self.train_keys = self.fix_keys(self.train_keys, dataset_filename)\n",
    "        self.test_keys = self.fix_keys(self.test_keys, dataset_filename)\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def load_model(self, model_filename):\n",
    "        self.model.load_state_dict(torch.load(model_filename, map_location=lambda storage, loc: storage))\n",
    "        return\n",
    "\n",
    "\n",
    "    def initialize(self, cuda_device=None):\n",
    "        rnd_seed = 12345\n",
    "        random.seed(rnd_seed)\n",
    "        np.random.seed(rnd_seed)\n",
    "        torch.manual_seed(rnd_seed)\n",
    "\n",
    "        self.model = VASNet()\n",
    "        self.model.eval()\n",
    "        self.model.apply(weights_init)\n",
    "        #print(self.model)\n",
    "\n",
    "        cuda_device = cuda_device or self.hps.cuda_device\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            print(\"Setting CUDA device: \",cuda_device)\n",
    "            torch.cuda.set_device(cuda_device)\n",
    "            torch.cuda.manual_seed(rnd_seed)\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            self.model.cuda()\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def get_data(self, key):\n",
    "        key_parts = key.split('/')\n",
    "        assert len(key_parts) == 2, \"ERROR. Wrong key name: \"+key\n",
    "        dataset, key = key_parts\n",
    "        return self.datasets[dataset][key]\n",
    "\n",
    "    def lookup_weights_file(self, data_path):\n",
    "        dataset_type_str = '' if self.dataset_type == '' else self.dataset_type + '_'\n",
    "        weights_filename = data_path + '/models/{}_{}splits_{}_*.tar.pth'.format(self.dataset_name, dataset_type_str, self.split_id)\n",
    "        weights_filename = glob.glob(weights_filename)\n",
    "        if len(weights_filename) == 0:\n",
    "            print(\"Couldn't find model weights: \", weights_filename)\n",
    "            return ''\n",
    "\n",
    "        # Get the first weights filename in the dir\n",
    "        weights_filename = weights_filename[0]\n",
    "        splits_file = data_path + '/splits/{}_{}splits.json'.format(self.dataset_name, dataset_type_str)\n",
    "\n",
    "        return weights_filename, splits_file\n",
    "\n",
    "\n",
    "    def train(self, output_dir='EX-0'):\n",
    "\n",
    "        print(\"Initializing VASNet model and optimizer...\")\n",
    "        self.model.train()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "        max_val_fscore = 0\n",
    "        max_val_fscore_epoch = 0\n",
    "        train_keys = self.train_keys[:]\n",
    "\n",
    "        lr = self.hps.lr[0]\n",
    "        for epoch in range(self.hps.epochs_max):\n",
    "\n",
    "            print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='')\n",
    "            self.model.train()\n",
    "            avg_loss = []\n",
    "\n",
    "            random.shuffle(train_keys)\n",
    "\n",
    "            for i, key in enumerate(train_keys):\n",
    "                dataset = self.get_data(key)\n",
    "                seq = dataset['features'][...]\n",
    "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "                target = dataset['gtscore'][...]\n",
    "                target = torch.from_numpy(target).unsqueeze(0)\n",
    "\n",
    "                # Normalize frame scores\n",
    "                target -= target.min()\n",
    "                target /= target.max()\n",
    "\n",
    "                if self.hps.use_cuda:\n",
    "                    seq, target = seq.float().cuda(), target.float().cuda()\n",
    "\n",
    "                seq_len = seq.shape[1]\n",
    "                y, _ = self.model(seq,seq_len)\n",
    "                loss_att = 0\n",
    "\n",
    "                loss = criterion(y, target)\n",
    "                # loss2 = y.sum()/seq_len\n",
    "                loss = loss + loss_att\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                avg_loss.append([float(loss), float(loss_att)])\n",
    "\n",
    "            # Evaluate test dataset\n",
    "            val_fscore, video_scores = self.eval(self.test_keys)\n",
    "            if max_val_fscore < val_fscore:\n",
    "                max_val_fscore = val_fscore\n",
    "                max_val_fscore_epoch = epoch\n",
    "\n",
    "            avg_loss = np.array(avg_loss)\n",
    "            print(\"   Train loss: {0:.05f}\".format(np.mean(avg_loss[:, 0])), end='')\n",
    "            print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))\n",
    "\n",
    "            if self.verbose:\n",
    "                video_scores = [[\"No\", \"Video\", \"F-score\"]] + video_scores\n",
    "                print_table(video_scores, cell_width=[3,40,8])\n",
    "\n",
    "            # Save model weights\n",
    "            path, filename = os.path.split(self.split_file)\n",
    "            base_filename, _ = os.path.splitext(filename)\n",
    "            path = os.path.join(output_dir, 'models_temp', base_filename+'_'+str(self.split_id))\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            filename = str(epoch)+'_'+str(round(val_fscore*100,3))+'.pth.tar'\n",
    "            torch.save(self.model.state_dict(), os.path.join(path, filename))\n",
    "\n",
    "        return max_val_fscore, max_val_fscore_epoch\n",
    "\n",
    "\n",
    "    def eval(self, keys, results_filename=None):\n",
    "\n",
    "        self.model.eval()\n",
    "        summary = {}\n",
    "        att_vecs = {}\n",
    "        with torch.no_grad():\n",
    "            for i, key in enumerate(keys):\n",
    "                data = self.get_data(key)\n",
    "                # seq = self.dataset[key]['features'][...]\n",
    "                seq = data['features'][...]\n",
    "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "\n",
    "                if self.hps.use_cuda:\n",
    "                    seq = seq.float().cuda()\n",
    "\n",
    "                y, att_vec = self.model(seq, seq.shape[1])\n",
    "                summary[key] = y[0].detach().cpu().numpy()\n",
    "                att_vecs[key] = att_vec.detach().cpu().numpy()\n",
    "\n",
    "        f_score, video_scores = self.eval_summary(summary, keys, metric=self.dataset_name,\n",
    "                    results_filename=results_filename, att_vecs=att_vecs)\n",
    "\n",
    "        return f_score, video_scores\n",
    "\n",
    "\n",
    "    def eval_summary(self, machine_summary_activations, test_keys, results_filename=None, metric='tvsum', att_vecs=None):\n",
    "\n",
    "        eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
    "\n",
    "        if results_filename is not None:\n",
    "            h5_res = h5py.File(results_filename, 'w')\n",
    "\n",
    "        fms = []\n",
    "        video_scores = []\n",
    "        for key_idx, key in enumerate(test_keys):\n",
    "            d = self.get_data(key)\n",
    "            probs = machine_summary_activations[key]\n",
    "\n",
    "            if 'change_points' not in d:\n",
    "                print(\"ERROR: No change points in dataset/video \",key)\n",
    "\n",
    "            cps = d['change_points'][...]\n",
    "            num_frames = d['n_frames'][()]\n",
    "            nfps = d['n_frame_per_seg'][...].tolist()\n",
    "            positions = d['picks'][...]\n",
    "            user_summary = d['user_summary'][...]\n",
    "\n",
    "            machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "            fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "            fms.append(fm)\n",
    "\n",
    "            # Reporting & logging\n",
    "            video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fm)])\n",
    "\n",
    "            if results_filename:\n",
    "                gt = d['gtscore'][...]\n",
    "                h5_res.create_dataset(key + '/score', data=probs)\n",
    "                h5_res.create_dataset(key + '/machine_summary', data=machine_summary)\n",
    "                h5_res.create_dataset(key + '/gtscore', data=gt)\n",
    "                h5_res.create_dataset(key + '/fm', data=fm)\n",
    "                h5_res.create_dataset(key + '/picks', data=positions)\n",
    "\n",
    "                video_name = key.split('/')[1]\n",
    "                if 'video_name' in d:\n",
    "                    video_name = d['video_name'][...]\n",
    "                h5_res.create_dataset(key + '/video_name', data=video_name)\n",
    "\n",
    "                if att_vecs is not None:\n",
    "                    h5_res.create_dataset(key + '/att', data=att_vecs[key])\n",
    "\n",
    "        mean_fm = np.mean(fms)\n",
    "\n",
    "        # Reporting & logging\n",
    "        if results_filename is not None:\n",
    "            h5_res.close()\n",
    "\n",
    "        return mean_fm, video_scores\n",
    "\n",
    "\n",
    "#==============================================================================================\n",
    "\n",
    "\n",
    "\n",
    "def eval_split(hps, splits_filename, data_dir='test'):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    ao = AONet(hps)\n",
    "    ao.initialize()\n",
    "    ao.load_datasets()\n",
    "    ao.load_split_file(splits_filename)\n",
    "\n",
    "    val_fscores = []\n",
    "    for split_id in range(len(ao.splits)):\n",
    "        ao.select_split(split_id)\n",
    "        weights_filename, _ = ao.lookup_weights_file(data_dir)\n",
    "        print(\"Loading model:\", weights_filename)\n",
    "        ao.load_model(weights_filename)\n",
    "        val_fscore, video_scores = ao.eval(ao.test_keys)\n",
    "        val_fscores.append(val_fscore)\n",
    "\n",
    "        val_fscore_avg = np.mean(val_fscores)\n",
    "\n",
    "        if hps.verbose:\n",
    "            video_scores = [[\"No.\", \"Video\", \"F-score\"]] + video_scores\n",
    "            print_table(video_scores, cell_width=[4,45,5])\n",
    "\n",
    "        print(\"Avg F-score: \", val_fscore)\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Total AVG F-score: \", val_fscore_avg)\n",
    "    return val_fscore_avg\n",
    "\n",
    "\n",
    "def train(hps):\n",
    "    os.makedirs(hps.output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(hps.output_dir, 'splits'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(hps.output_dir, 'code'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(hps.output_dir, 'models'), exist_ok=True)\n",
    "    os.system('cp -f splits/*.json  ' + hps.output_dir + '/splits/')\n",
    "    os.system('cp *.py ' + hps.output_dir + '/code/')\n",
    "\n",
    "    # Create a file to collect results from all splits\n",
    "    f = open(hps.output_dir + '/results.txt', 'wt')\n",
    "\n",
    "    for split_filename in hps.splits:\n",
    "        dataset_name, dataset_type, splits = parse_splits_filename(split_filename)\n",
    "\n",
    "        # For no augmentation use only a dataset corresponding to the split file\n",
    "        datasets = None\n",
    "        if dataset_type == '':\n",
    "            datasets = hps.get_dataset_by_name(dataset_name)\n",
    "\n",
    "        if datasets is None:\n",
    "            datasets = hps.datasets\n",
    "\n",
    "        f_avg = 0\n",
    "        n_folds = len(splits)\n",
    "        for split_id in range(n_folds):\n",
    "            ao = AONet(hps)\n",
    "            ao.initialize()\n",
    "            ao.load_datasets(datasets=datasets)\n",
    "            ao.load_split_file(splits_file=split_filename)\n",
    "            ao.select_split(split_id=split_id)\n",
    "\n",
    "            fscore, fscore_epoch = ao.train(output_dir=hps.output_dir)\n",
    "            f_avg += fscore\n",
    "\n",
    "            # Log F-score for this split_id\n",
    "            f.write(split_filename + ', ' + str(split_id) + ', ' + str(fscore) + ', ' + str(fscore_epoch) + '\\n')\n",
    "            f.flush()\n",
    "\n",
    "            # Save model with the highest F score\n",
    "            _, log_file = os.path.split(split_filename)\n",
    "            log_dir, _ = os.path.splitext(log_file)\n",
    "            log_dir += '_' + str(split_id)\n",
    "            log_file = os.path.join(hps.output_dir, 'models', log_dir) + '_' + str(fscore) + '.tar.pth'\n",
    "\n",
    "            os.makedirs(os.path.join(hps.output_dir, 'models', ), exist_ok=True)\n",
    "            os.system('mv ' + hps.output_dir + '/models_temp/' + log_dir + '/' + str(fscore_epoch) + '_*.pth.tar ' + log_file)\n",
    "            os.system('rm -rf ' + hps.output_dir + '/models_temp/' + log_dir)\n",
    "\n",
    "            print(\"Split: {0:}   Best F-score: {1:0.5f}   Model: {2:}\".format(split_filename, fscore, log_file))\n",
    "\n",
    "        # Write average F-score for all splits to the results.txt file\n",
    "        f_avg /= n_folds\n",
    "        f.write(split_filename + ', ' + str('avg') + ', ' + str(f_avg) + '\\n')\n",
    "        f.flush()\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = HParameters()\n",
    "vasnet = AONet(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasnet.initialize()\n",
    "vasnet.load_model('VASNet/data/models/tvsum_aug_splits_3_0.639623427142229.tar.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.googlenet(pretrained=True)\n",
    "gnet = nn.Sequential(*list(googlenet.children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([transforms.ToPILImage(mode=None),transforms.Resize((224,224)),transforms.transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeThumbnails(shot_bounds, vid_path, store = True, all=True):\n",
    "    \"\"\"Returns list of key_frames in numpy array format, one for each shot \n",
    "       and the timestamps of these key_frames\n",
    "       \n",
    "       :store: store the extracted thumbnails in a new directory\n",
    "       :all: extract thumbnails for all shots\"\"\"\n",
    "    # Taking centre frame of each shot - creating a list of such \n",
    "    # centre frames from the extracted shot boundaries\n",
    "    vasnet.model.eval()\n",
    "    file_name = os.path.basename(vid_path).split('.')[0]\n",
    "    bound1 = 0\n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    \n",
    "    if(all==True):\n",
    "        loop = len(shot_bounds) + 1\n",
    "    else:\n",
    "        loop = 1\n",
    "        \n",
    "    for i in tqdm(range(loop)): # For every shot\n",
    "        if(i != len(shot_bounds)): # not last boundary\n",
    "            bound2 = shot_bounds[i]\n",
    "            \n",
    "        else: #last boundary\n",
    "            vidcap.set(cv2.CAP_PROP_POS_AVI_RATIO,1)\n",
    "            bound2 = vidcap.get(cv2.CAP_PROP_POS_MSEC) #max duration\n",
    "\n",
    "        #Getting frame importances\n",
    "        curr_time = bound1\n",
    "        tensors = []\n",
    "        images = []        \n",
    "        while(curr_time<=bound2): \n",
    "            vidcap.set(cv2.CAP_PROP_POS_MSEC,curr_time)\n",
    "            _,image = vidcap.read()\n",
    "            images.append(image)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            img_tensor = tfms(image) #converting to torch tensor\n",
    "            img_tensor = img_tensor.unsqueeze(0)\n",
    "            tensors.append(img_tensor)\n",
    "            curr_time += 500 #2 FPS => skip 0.5 seconds\n",
    "            \n",
    "        #'tensors' now contains a list of frames taken as torch.tensors\n",
    "        inp = torch.cat(tensors,0) #concatenating into a 4D tensor\n",
    "        features = gnet(inp) #Feature extraction\n",
    "        \n",
    "        features = features.reshape([1,-1,1024]).float()\n",
    "        importances = vasnet.model(features)[0] #Performing video summarization\n",
    "        \n",
    "        thumbnail_idx = int(torch.argmax(importances))\n",
    "        thumbnail = images[thumbnail_idx] #Thumbnail is the frame with maximum importance\n",
    "        \n",
    "        if (store==True): #Storing thumbnail\n",
    "            if not (os.path.isdir(file_name+'_summary_frames')):\n",
    "                os.mkdir(file_name+'_summary_frames')\n",
    "            cv2.imwrite(\"{}/shot_{}_time_{}.jpg\".format(file_name+'_summary_frames',i,bound1 + 500*thumbnail_idx),thumbnail)\n",
    "        \n",
    "        bound1 = bound2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotbounds = shot_boundaries(\"../data/SAA_clip.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [06:46<00:00,  3.00it/s] \n"
     ]
    }
   ],
   "source": [
    "storeThumbnails(shotbounds,\"../data/SAA_clip.mp4\",all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(frame1, frame2):\n",
    "    \"\"\"Returns\n",
    "    SSIM similarity between two images\"\"\"\n",
    "    #s = measure.compare_mse(frame1, frame2)\n",
    "    s = measure.compare_ssim(frame1, frame2, multichannel=True)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarities(vid_path):\n",
    "    \"\"\"Returns list of similarities of consecutive frames in the video and its fps\"\"\"\n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"FPS of the video: {}\".formatfps)\n",
    "    success, frame1 = vidcap.read()\n",
    "    sims = []\n",
    "    count = 0\n",
    "    while success:\n",
    "        success, frame2 = vidcap.read()\n",
    "        if success:\n",
    "            sim = similarity(frame1, frame2)\n",
    "            sims.append(sim)\n",
    "            print(\"At frame {}: similarity = {}\".format(count, sim))\n",
    "            frame1 = frame2\n",
    "            count += 1\n",
    "    #Plotting time vs similarities\n",
    "    plt.plot([x/fps for x in range(count)], sims)\n",
    "    plt.show()\n",
    "    return sims, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sims,_ = similarities(\"../data/SAA_clip.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sims_inv = [1-x for x in sims] # Difference = 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x/fps for x in range(len(sims))], sims_inv) #Video time vs frame_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_key_frames(vid_path):\n",
    "    \"\"\"Stores key frames of the video in a new directory\"\"\"\n",
    "    shot_bounds = shot_boundaries(vid_path)\n",
    "    return shot_bounds, get_key_frames(shot_bounds,vid_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = store_key_frames(\"../data/SAA_clip.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imagecluster import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no fingerprints database faces/imagecluster/fingerprints.pk found\n",
      "create image array database faces/imagecluster/images.pk\n",
      "faces/t00:14:02f0.jpg\n",
      "faces/t00:05:28f0.jpg\n",
      "faces/t00:11:54f0.jpg\n",
      "faces/t00:45:30f0.jpg\n",
      "faces/t00:27:47f0.jpg\n",
      "faces/t00:10:52f0.jpg\n",
      "faces/t00:09:08f1.jpg\n",
      "faces/t00:21:51f0.jpg\n",
      "faces/t00:45:10f0.jpg\n",
      "faces/t00:22:23f0.jpg\n",
      "faces/t00:28:53f0.jpg\n",
      "faces/t00:18:37f0.jpg\n",
      "faces/t00:28:03f0.jpg\n",
      "faces/t00:26:43f0.jpg\n",
      "faces/t00:04:24f1.jpg\n",
      "faces/t00:40:28f0.jpg\n",
      "faces/t00:50:05f0.jpg\n",
      "faces/t00:07:40f0.jpg\n",
      "faces/t00:37:10f1.jpg\n",
      "faces/t00:27:07f0.jpg\n",
      "faces/t00:22:27f0.jpg\n",
      "faces/t00:48:46f0.jpg\n",
      "faces/t00:40:30f0.jpg\n",
      "faces/t00:19:49f0.jpg\n",
      "faces/t00:48:36f0.jpg\n",
      "faces/t00:18:11f0.jpg\n",
      "faces/t00:17:37f0.jpg\n",
      "faces/t00:12:52f0.jpg\n",
      "faces/t00:33:17f0.jpg\n",
      "faces/t00:14:50f1.jpg\n",
      "faces/t00:10:26f0.jpg\n",
      "faces/t00:46:50f0.jpg\n",
      "faces/t00:26:39f0.jpg\n",
      "faces/t00:04:50f0.jpg\n",
      "faces/t00:45:46f0.jpg\n",
      "faces/t00:51:31f0.jpg\n",
      "faces/t00:47:50f0.jpg\n",
      "faces/t00:40:20f0.jpg\n",
      "faces/t00:23:35f0.jpg\n",
      "faces/t00:24:47f0.jpg\n",
      "faces/t00:26:31f0.jpg\n",
      "faces/t00:48:12f0.jpg\n",
      "faces/t00:11:42f0.jpg\n",
      "faces/t00:33:13f0.jpg\n",
      "faces/t00:17:55f0.jpg\n",
      "faces/t00:37:46f0.jpg\n",
      "faces/t00:00:34f0.jpg\n",
      "faces/t00:25:19f0.jpg\n",
      "faces/t00:37:16f0.jpg\n",
      "faces/t00:30:59f0.jpg\n",
      "faces/t00:40:52f0.jpg\n",
      "faces/t00:14:12f1.jpg\n",
      "faces/t00:01:48f0.jpg\n",
      "faces/t00:11:26f0.jpg\n",
      "faces/t00:46:12f1.jpg\n",
      "faces/t00:25:11f0.jpg\n",
      "faces/t00:26:45f0.jpg\n",
      "faces/t00:02:08f0.jpg\n",
      "faces/t00:45:32f0.jpg\n",
      "faces/t00:46:32f0.jpg\n",
      "faces/t00:25:09f0.jpg\n",
      "faces/t00:09:12f0.jpg\n",
      "faces/t00:47:10f0.jpg\n",
      "faces/t00:13:18f0.jpg\n",
      "faces/t00:05:48f0.jpg\n",
      "faces/t00:45:58f0.jpg\n",
      "faces/t00:48:48f1.jpg\n",
      "faces/t00:33:58f0.jpg\n",
      "faces/t00:01:30f0.jpg\n",
      "faces/t00:26:07f0.jpg\n",
      "faces/t00:02:22f0.jpg\n",
      "faces/t00:51:53f0.jpg\n",
      "faces/t00:37:42f0.jpg\n",
      "faces/t00:41:24f0.jpg\n",
      "faces/t00:26:01f0.jpg\n",
      "faces/t00:47:46f0.jpg\n",
      "faces/t00:09:20f0.jpg\n",
      "faces/t00:18:25f0.jpg\n",
      "faces/t00:04:16f1.jpg\n",
      "faces/t00:48:54f0.jpg\n",
      "faces/t00:45:54f1.jpg\n",
      "faces/t00:49:04f0.jpg\n",
      "faces/t00:21:03f0.jpg\n",
      "faces/t00:24:07f0.jpg\n",
      "faces/t00:30:57f0.jpg\n",
      "faces/t00:28:31f0.jpg\n",
      "faces/t00:45:06f0.jpg\n",
      "faces/t00:28:51f1.jpg\n",
      "faces/t00:21:13f0.jpg\n",
      "faces/t00:34:52f0.jpg\n",
      "faces/t00:32:15f0.jpg\n",
      "faces/t00:09:06f1.jpg\n",
      "faces/t00:17:47f0.jpg\n",
      "faces/t00:34:02f1.jpg\n",
      "faces/t00:24:05f0.jpg\n",
      "faces/t00:40:32f0.jpg\n",
      "faces/t00:09:00f0.jpg\n",
      "faces/t00:39:58f0.jpg\n",
      "faces/t00:13:56f0.jpg\n",
      "faces/t00:45:20f0.jpg\n",
      "faces/t00:47:18f0.jpg\n",
      "faces/t00:28:05f0.jpg\n",
      "faces/t00:37:12f0.jpg\n",
      "faces/t00:28:55f0.jpg\n",
      "faces/t00:49:12f0.jpg\n",
      "faces/t00:33:26f1.jpg\n",
      "faces/t00:21:37f0.jpg\n",
      "faces/t00:36:58f0.jpg\n",
      "faces/t00:33:22f0.jpg\n",
      "faces/t00:37:04f0.jpg\n",
      "faces/t00:10:56f0.jpg\n",
      "faces/t00:13:10f0.jpg\n",
      "faces/t00:18:35f0.jpg\n",
      "faces/t00:12:34f0.jpg\n",
      "faces/t00:34:00f0.jpg\n",
      "faces/t00:18:27f0.jpg\n",
      "faces/t00:49:18f0.jpg\n",
      "faces/t00:19:51f0.jpg\n",
      "faces/t00:52:09f0.jpg\n",
      "faces/t00:33:52f0.jpg\n",
      "faces/t00:50:03f0.jpg\n",
      "faces/t00:21:29f1.jpg\n",
      "faces/t00:20:57f0.jpg\n",
      "faces/t00:32:13f0.jpg\n",
      "faces/t00:47:02f0.jpg\n",
      "faces/t00:14:36f0.jpg\n",
      "faces/t00:26:59f0.jpg\n",
      "faces/t00:08:42f0.jpg\n",
      "faces/t00:18:13f0.jpg\n",
      "faces/t00:48:16f0.jpg\n",
      "faces/t00:18:33f0.jpg\n",
      "faces/t00:39:48f0.jpg\n",
      "faces/t00:04:02f0.jpg\n",
      "faces/t00:28:49f1.jpg\n",
      "faces/t00:09:14f0.jpg\n",
      "faces/t00:27:05f0.jpg\n",
      "faces/t00:47:40f0.jpg\n",
      "faces/t00:49:08f1.jpg\n",
      "faces/t00:11:48f0.jpg\n",
      "faces/t00:49:08f0.jpg\n",
      "faces/t00:25:53f0.jpg\n",
      "faces/t00:27:51f0.jpg\n",
      "faces/t00:12:28f0.jpg\n",
      "faces/t00:18:51f0.jpg\n",
      "faces/t00:37:18f0.jpg\n",
      "faces/t00:10:48f1.jpg\n",
      "faces/t00:28:45f1.jpg\n",
      "faces/t00:34:18f0.jpg\n",
      "faces/t00:22:25f0.jpg\n",
      "faces/t00:28:21f0.jpg\n",
      "faces/t00:48:58f0.jpg\n",
      "faces/t00:47:22f0.jpg\n",
      "faces/t00:11:40f0.jpg\n",
      "faces/t00:08:20f0.jpg\n",
      "faces/t00:13:14f0.jpg\n",
      "faces/t00:25:05f0.jpg\n",
      "faces/t00:21:15f0.jpg\n",
      "faces/t00:40:02f0.jpg\n",
      "faces/t00:27:59f0.jpg\n",
      "faces/t00:30:13f0.jpg\n",
      "faces/t00:46:16f0.jpg\n",
      "faces/t00:47:00f0.jpg\n",
      "faces/t00:47:24f0.jpg\n",
      "faces/t00:16:00f0.jpg\n",
      "faces/t00:12:50f0.jpg\n",
      "faces/t00:08:56f0.jpg\n",
      "faces/t00:07:06f0.jpg\n",
      "faces/t00:11:58f0.jpg\n",
      "faces/t00:45:06f2.jpg\n",
      "faces/t00:39:40f0.jpg\n",
      "faces/t00:40:14f0.jpg\n",
      "faces/t00:12:02f0.jpg\n",
      "faces/t00:45:50f0.jpg\n",
      "faces/t00:19:01f0.jpg\n",
      "faces/t00:32:11f0.jpg\n",
      "faces/t00:13:20f0.jpg\n",
      "faces/t00:28:27f0.jpg\n",
      "faces/t00:10:22f0.jpg\n",
      "faces/t00:18:01f0.jpg\n",
      "faces/t00:51:39f1.jpg\n",
      "faces/t00:23:59f0.jpg\n",
      "faces/t00:17:31f0.jpg\n",
      "faces/t00:17:57f0.jpg\n",
      "faces/t00:25:07f0.jpg\n",
      "faces/t00:04:34f0.jpg\n",
      "faces/t00:00:42f0.jpg\n",
      "faces/t00:25:21f0.jpg\n",
      "faces/t00:46:56f0.jpg\n",
      "faces/t00:27:57f0.jpg\n",
      "faces/t00:04:52f0.jpg\n",
      "faces/t00:32:07f0.jpg\n",
      "faces/t00:28:15f0.jpg\n",
      "faces/t00:48:28f0.jpg\n",
      "faces/t00:48:40f0.jpg\n",
      "faces/t00:51:59f0.jpg\n",
      "faces/t00:48:56f0.jpg\n",
      "faces/t00:25:13f1.jpg\n",
      "faces/t00:15:10f0.jpg\n",
      "faces/t00:04:04f0.jpg\n",
      "faces/t00:51:37f0.jpg\n",
      "faces/t00:19:03f1.jpg\n",
      "faces/t00:46:04f0.jpg\n",
      "faces/t00:52:19f0.jpg\n",
      "faces/t00:40:54f0.jpg\n",
      "faces/t00:49:10f1.jpg\n",
      "faces/t00:47:08f0.jpg\n",
      "faces/t00:15:24f1.jpg\n",
      "faces/t00:24:49f0.jpg\n",
      "faces/t00:18:45f0.jpg\n",
      "faces/t00:39:02f0.jpg\n",
      "faces/t00:07:02f0.jpg\n",
      "faces/t00:33:54f0.jpg\n",
      "faces/t00:24:21f0.jpg\n",
      "faces/t00:14:00f0.jpg\n",
      "faces/t00:34:14f0.jpg\n",
      "faces/t00:47:14f0.jpg\n",
      "faces/t00:51:41f0.jpg\n",
      "faces/t00:46:40f0.jpg\n",
      "faces/t00:01:18f0.jpg\n",
      "faces/t00:00:32f1.jpg\n",
      "faces/t00:02:18f0.jpg\n",
      "faces/t00:09:40f0.jpg\n",
      "faces/t00:21:31f0.jpg\n",
      "faces/t00:52:01f0.jpg\n",
      "faces/t00:09:38f0.jpg\n",
      "faces/t00:37:06f0.jpg\n",
      "faces/t00:00:36f0.jpg\n",
      "faces/t00:41:28f0.jpg\n",
      "faces/t00:48:10f0.jpg\n",
      "faces/t00:04:30f0.jpg\n",
      "faces/t00:34:00f1.jpg\n",
      "faces/t00:17:35f0.jpg\n",
      "faces/t00:40:12f0.jpg\n",
      "faces/t00:50:57f0.jpg\n",
      "faces/t00:19:47f0.jpg\n",
      "faces/t00:18:59f0.jpg\n",
      "faces/t00:39:36f0.jpg\n",
      "faces/t00:24:23f0.jpg\n",
      "faces/t00:04:42f0.jpg\n",
      "faces/t00:17:45f1.jpg\n",
      "faces/t00:20:51f0.jpg\n",
      "faces/t00:40:42f0.jpg\n",
      "faces/t00:26:15f0.jpg\n",
      "faces/t00:04:18f0.jpg\n",
      "faces/t00:33:56f0.jpg\n",
      "faces/t00:45:56f0.jpg\n",
      "faces/t00:18:43f0.jpg\n",
      "faces/t00:07:38f0.jpg\n",
      "faces/t00:09:06f0.jpg\n",
      "faces/t00:21:35f0.jpg\n",
      "faces/t00:05:50f0.jpg\n",
      "faces/t00:45:36f0.jpg\n",
      "faces/t00:31:39f0.jpg\n",
      "faces/t00:26:47f0.jpg\n",
      "faces/t00:28:47f0.jpg\n",
      "faces/t00:34:22f0.jpg\n",
      "faces/t00:05:24f0.jpg\n",
      "faces/t00:00:44f0.jpg\n",
      "faces/t00:25:55f0.jpg\n",
      "faces/t00:05:22f0.jpg\n",
      "faces/t00:32:17f0.jpg\n",
      "faces/t00:10:34f0.jpg\n",
      "faces/t00:28:19f0.jpg\n",
      "faces/t00:34:20f0.jpg\n",
      "faces/t00:15:34f0.jpg\n",
      "faces/t00:18:15f0.jpg\n",
      "faces/t00:00:38f1.jpg\n",
      "faces/t00:47:38f1.jpg\n",
      "faces/t00:46:22f0.jpg\n",
      "faces/t00:18:31f0.jpg\n",
      "faces/t00:46:30f0.jpg\n",
      "faces/t00:33:11f0.jpg\n",
      "faces/t00:20:59f0.jpg\n",
      "faces/t00:12:58f0.jpg\n",
      "faces/t00:05:14f0.jpg\n",
      "faces/t00:07:36f0.jpg\n",
      "faces/t00:05:56f0.jpg\n",
      "faces/t00:15:08f0.jpg\n",
      "faces/t00:01:44f0.jpg\n",
      "faces/t00:12:42f0.jpg\n",
      "faces/t00:26:51f0.jpg\n",
      "faces/t00:08:54f0.jpg\n",
      "faces/t00:28:51f0.jpg\n",
      "faces/t00:18:09f0.jpg\n",
      "faces/t00:28:33f0.jpg\n",
      "faces/t00:38:56f0.jpg\n",
      "faces/t00:26:05f0.jpg\n",
      "faces/t00:33:26f0.jpg\n",
      "faces/t00:25:57f0.jpg\n",
      "faces/t00:01:38f0.jpg\n",
      "faces/t00:48:52f0.jpg\n",
      "faces/t00:47:42f1.jpg\n",
      "faces/t00:47:06f0.jpg\n",
      "faces/t00:08:44f0.jpg\n",
      "faces/t00:18:19f0.jpg\n",
      "faces/t00:01:20f0.jpg\n",
      "faces/t00:01:34f0.jpg\n",
      "faces/t00:04:20f0.jpg\n",
      "faces/t00:34:04f1.jpg\n",
      "faces/t00:39:00f0.jpg\n",
      "faces/t00:26:17f0.jpg\n",
      "faces/t00:12:26f0.jpg\n",
      "faces/t00:17:33f0.jpg\n",
      "faces/t00:33:50f0.jpg\n",
      "faces/t00:47:12f0.jpg\n",
      "faces/t00:28:43f0.jpg\n",
      "faces/t00:25:17f0.jpg\n",
      "faces/t00:04:22f0.jpg\n",
      "faces/t00:06:52f0.jpg\n",
      "faces/t00:26:57f0.jpg\n",
      "faces/t00:04:48f0.jpg\n",
      "faces/t00:39:04f0.jpg\n",
      "faces/t00:14:04f0.jpg\n",
      "faces/t00:48:26f0.jpg\n",
      "faces/t00:45:40f0.jpg\n",
      "faces/t00:24:03f0.jpg\n",
      "faces/t00:15:58f0.jpg\n",
      "faces/t00:05:16f0.jpg\n",
      "faces/t00:24:19f0.jpg\n",
      "faces/t00:45:38f0.jpg\n",
      "faces/t00:27:21f0.jpg\n",
      "faces/t00:04:26f0.jpg\n",
      "faces/t00:09:42f0.jpg\n",
      "faces/t00:01:46f0.jpg\n",
      "faces/t00:11:30f0.jpg\n",
      "faces/t00:13:20f1.jpg\n",
      "faces/t00:05:36f0.jpg\n",
      "faces/t00:48:32f0.jpg\n",
      "faces/t00:12:54f0.jpg\n",
      "faces/t00:41:04f0.jpg\n",
      "faces/t00:17:29f0.jpg\n",
      "faces/t00:27:09f0.jpg\n",
      "faces/t00:14:12f0.jpg\n",
      "faces/t00:01:24f0.jpg\n",
      "faces/t00:10:28f0.jpg\n",
      "faces/t00:28:49f0.jpg\n",
      "faces/t00:17:43f0.jpg\n",
      "faces/t00:48:38f0.jpg\n",
      "faces/t00:37:02f0.jpg\n",
      "faces/t00:21:05f0.jpg\n",
      "faces/t00:11:14f0.jpg\n",
      "faces/t00:49:14f0.jpg\n",
      "faces/t00:04:50f1.jpg\n",
      "faces/t00:48:22f0.jpg\n",
      "faces/t00:28:41f1.jpg\n",
      "faces/t00:46:08f1.jpg\n",
      "faces/t00:26:09f0.jpg\n",
      "faces/t00:10:48f0.jpg\n",
      "faces/t00:09:18f0.jpg\n",
      "faces/t00:23:49f0.jpg\n",
      "faces/t00:25:13f0.jpg\n",
      "faces/t00:12:32f0.jpg\n",
      "faces/t00:13:52f0.jpg\n",
      "faces/t00:13:58f0.jpg\n",
      "faces/t00:45:18f0.jpg\n",
      "faces/t00:19:55f0.jpg\n",
      "faces/t00:27:53f0.jpg\n",
      "faces/t00:24:31f0.jpg\n",
      "faces/t00:52:19f1.jpg\n",
      "faces/t00:34:02f0.jpg\n",
      "faces/t00:44:28f0.jpg\n",
      "faces/t00:33:15f1.jpg\n",
      "faces/t00:45:44f0.jpg\n",
      "faces/t00:07:00f0.jpg\n",
      "faces/t00:04:06f0.jpg\n",
      "faces/t00:21:33f0.jpg\n",
      "faces/t00:46:00f0.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces/t00:37:00f0.jpg\n",
      "faces/t00:41:14f0.jpg\n",
      "faces/t00:46:54f0.jpg\n",
      "faces/t00:14:26f0.jpg\n",
      "faces/t00:47:46f1.jpg\n",
      "faces/t00:02:02f0.jpg\n",
      "faces/t00:28:25f0.jpg\n",
      "faces/t00:39:38f0.jpg\n",
      "faces/t00:16:02f0.jpg\n",
      "faces/t00:12:24f0.jpg\n",
      "faces/t00:18:39f0.jpg\n",
      "faces/t00:09:28f0.jpg\n",
      "faces/t00:07:50f0.jpg\n",
      "faces/t00:00:36f2.jpg\n",
      "faces/t00:15:38f0.jpg\n",
      "faces/t00:14:48f1.jpg\n",
      "faces/t00:46:46f0.jpg\n",
      "faces/t00:28:41f0.jpg\n",
      "faces/t00:07:46f0.jpg\n",
      "faces/t00:26:49f0.jpg\n",
      "faces/t00:26:03f0.jpg\n",
      "faces/t00:40:24f0.jpg\n",
      "faces/t00:04:32f0.jpg\n",
      "faces/t00:09:36f0.jpg\n",
      "faces/t00:02:48f0.jpg\n",
      "faces/t00:17:39f0.jpg\n",
      "faces/t00:14:10f0.jpg\n",
      "faces/t00:06:54f0.jpg\n",
      "faces/t00:18:03f0.jpg\n",
      "faces/t00:03:04f0.jpg\n",
      "faces/t00:28:11f0.jpg\n",
      "faces/t00:00:36f1.jpg\n",
      "faces/t00:49:12f1.jpg\n",
      "faces/t00:11:04f0.jpg\n",
      "faces/t00:04:18f1.jpg\n",
      "faces/t00:21:27f0.jpg\n",
      "faces/t00:11:50f0.jpg\n",
      "faces/t00:07:42f0.jpg\n",
      "faces/t00:37:14f0.jpg\n",
      "faces/t00:33:32f0.jpg\n",
      "faces/t00:26:27f0.jpg\n",
      "faces/t00:03:00f0.jpg\n",
      "faces/t00:25:15f1.jpg\n",
      "faces/t00:46:20f1.jpg\n",
      "faces/t00:18:05f0.jpg\n",
      "faces/t00:28:17f0.jpg\n",
      "faces/t00:48:48f0.jpg\n",
      "faces/t00:19:45f0.jpg\n",
      "faces/t00:46:24f0.jpg\n",
      "faces/t00:37:50f0.jpg\n",
      "faces/t00:18:29f0.jpg\n",
      "faces/t00:37:54f0.jpg\n",
      "faces/t00:39:08f0.jpg\n",
      "faces/t00:48:50f1.jpg\n",
      "faces/t00:27:23f0.jpg\n",
      "faces/t00:51:55f0.jpg\n",
      "faces/t00:28:55f1.jpg\n",
      "faces/t00:48:46f1.jpg\n",
      "faces/t00:37:40f0.jpg\n",
      "faces/t00:10:54f0.jpg\n",
      "faces/t00:46:34f0.jpg\n",
      "faces/t00:00:04f0.jpg\n",
      "faces/t00:11:52f0.jpg\n",
      "faces/t00:06:58f0.jpg\n",
      "faces/t00:15:30f0.jpg\n",
      "faces/t00:46:10f1.jpg\n",
      "faces/t00:37:48f0.jpg\n",
      "faces/t00:26:33f0.jpg\n",
      "faces/t00:04:26f1.jpg\n",
      "faces/t00:23:37f0.jpg\n",
      "faces/t00:49:16f1.jpg\n",
      "faces/t00:46:20f0.jpg\n",
      "faces/t00:09:16f0.jpg\n",
      "faces/t00:50:39f0.jpg\n",
      "faces/t00:26:11f0.jpg\n",
      "faces/t00:11:08f0.jpg\n",
      "faces/t00:26:29f0.jpg\n",
      "faces/t00:49:10f0.jpg\n",
      "faces/t00:08:58f0.jpg\n",
      "faces/t00:10:46f0.jpg\n",
      "faces/t00:49:00f0.jpg\n",
      "faces/t00:18:41f0.jpg\n",
      "faces/t00:25:15f0.jpg\n",
      "faces/t00:47:16f0.jpg\n",
      "faces/t00:09:02f0.jpg\n",
      "faces/t00:47:36f1.jpg\n",
      "faces/t00:49:20f0.jpg\n",
      "faces/t00:49:02f0.jpg\n",
      "faces/t00:03:20f0.jpg\n",
      "faces/t00:06:36f0.jpg\n",
      "faces/t00:48:50f0.jpg\n",
      "faces/t00:04:40f0.jpg\n",
      "faces/t00:40:26f0.jpg\n",
      "faces/t00:18:23f0.jpg\n",
      "faces/t00:27:03f0.jpg\n",
      "faces/t00:11:06f0.jpg\n",
      "faces/t00:05:30f0.jpg\n",
      "faces/t00:43:16f0.jpg\n",
      "faces/t00:17:59f0.jpg\n",
      "faces/t00:28:07f0.jpg\n",
      "faces/t00:46:10f0.jpg\n",
      "faces/t00:47:42f0.jpg\n",
      "faces/t00:20:55f0.jpg\n",
      "faces/t00:25:17f1.jpg\n",
      "faces/t00:05:44f0.jpg\n",
      "faces/t00:32:09f0.jpg\n",
      "faces/t00:49:22f0.jpg\n",
      "faces/t00:13:06f0.jpg\n",
      "faces/t00:04:24f0.jpg\n",
      "faces/t00:47:48f0.jpg\n",
      "faces/t00:21:39f0.jpg\n",
      "faces/t00:28:29f0.jpg\n",
      "faces/t00:14:50f0.jpg\n",
      "faces/t00:19:07f0.jpg\n",
      "faces/t00:18:17f0.jpg\n",
      "faces/t00:26:25f0.jpg\n",
      "faces/t00:24:37f0.jpg\n",
      "faces/t00:31:21f0.jpg\n",
      "faces/t00:20:37f0.jpg\n",
      "faces/t00:05:52f0.jpg\n",
      "faces/t00:47:32f0.jpg\n",
      "faces/t00:09:48f0.jpg\n",
      "faces/t00:07:04f1.jpg\n",
      "faces/t00:19:59f0.jpg\n",
      "faces/t00:47:26f0.jpg\n",
      "faces/t00:51:39f0.jpg\n",
      "faces/t00:13:08f0.jpg\n",
      "faces/t00:01:26f0.jpg\n",
      "faces/t00:19:43f0.jpg\n",
      "faces/t00:41:32f0.jpg\n",
      "faces/t00:06:56f0.jpg\n",
      "faces/t00:34:08f0.jpg\n",
      "faces/t00:48:18f0.jpg\n",
      "faces/t00:20:01f0.jpg\n",
      "faces/t00:46:58f0.jpg\n",
      "faces/t00:21:49f0.jpg\n",
      "faces/t00:43:14f0.jpg\n",
      "faces/t00:02:18f1.jpg\n",
      "faces/t00:18:47f0.jpg\n",
      "faces/t00:47:36f0.jpg\n",
      "faces/t00:27:49f0.jpg\n",
      "faces/t00:11:16f0.jpg\n",
      "faces/t00:02:10f0.jpg\n",
      "faces/t00:41:06f0.jpg\n",
      "faces/t00:02:58f0.jpg\n",
      "faces/t00:04:46f0.jpg\n",
      "faces/t00:09:10f1.jpg\n",
      "faces/t00:45:42f0.jpg\n",
      "faces/t00:09:34f0.jpg\n",
      "faces/t00:46:28f0.jpg\n",
      "faces/t00:11:38f0.jpg\n",
      "faces/t00:20:29f0.jpg\n",
      "faces/t00:09:46f0.jpg\n",
      "faces/t00:39:06f0.jpg\n",
      "faces/t00:37:10f0.jpg\n",
      "faces/t00:24:25f0.jpg\n",
      "faces/t00:28:23f0.jpg\n",
      "faces/t00:02:20f0.jpg\n",
      "faces/t00:46:02f0.jpg\n",
      "faces/t00:18:49f0.jpg\n",
      "faces/t00:48:24f0.jpg\n",
      "faces/t00:37:38f0.jpg\n",
      "faces/t00:25:11f1.jpg\n",
      "faces/t00:48:20f0.jpg\n",
      "faces/t00:18:21f0.jpg\n",
      "faces/t00:17:27f0.jpg\n",
      "faces/t00:45:58f1.jpg\n",
      "faces/t00:10:38f0.jpg\n",
      "faces/t00:31:43f0.jpg\n",
      "faces/t00:05:20f0.jpg\n",
      "faces/t00:33:15f0.jpg\n",
      "faces/t00:04:20f1.jpg\n",
      "faces/t00:49:06f0.jpg\n",
      "faces/t00:45:56f1.jpg\n",
      "faces/t00:47:30f1.jpg\n",
      "faces/t00:38:58f0.jpg\n",
      "faces/t00:47:52f0.jpg\n",
      "faces/t00:34:54f0.jpg\n",
      "faces/t00:37:58f0.jpg\n",
      "faces/t00:04:38f0.jpg\n",
      "faces/t00:28:53f1.jpg\n",
      "faces/t00:19:03f0.jpg\n",
      "faces/t00:51:13f0.jpg\n",
      "faces/t00:09:32f0.jpg\n",
      "faces/t00:43:12f0.jpg\n",
      "faces/t00:02:54f0.jpg\n",
      "faces/t00:28:13f0.jpg\n",
      "faces/t00:04:14f0.jpg\n",
      "faces/t00:09:24f0.jpg\n",
      "faces/t00:08:16f0.jpg\n",
      "faces/t00:41:16f0.jpg\n",
      "faces/t00:12:20f0.jpg\n",
      "faces/t00:07:44f0.jpg\n",
      "faces/t00:41:36f0.jpg\n",
      "faces/t00:19:41f0.jpg\n",
      "faces/t00:12:56f0.jpg\n",
      "faces/t00:00:32f0.jpg\n",
      "faces/t00:21:31f1.jpg\n",
      "faces/t00:26:19f0.jpg\n",
      "faces/t00:05:34f0.jpg\n",
      "faces/t00:40:50f0.jpg\n",
      "faces/t00:19:53f0.jpg\n",
      "faces/t00:49:14f1.jpg\n",
      "faces/t00:13:12f0.jpg\n",
      "faces/t00:48:14f0.jpg\n",
      "faces/t00:45:06f1.jpg\n",
      "faces/t00:09:10f0.jpg\n",
      "faces/t00:04:12f0.jpg\n",
      "faces/t00:20:47f0.jpg\n",
      "faces/t00:10:24f0.jpg\n",
      "faces/t00:47:40f1.jpg\n",
      "faces/t00:47:34f0.jpg\n",
      "faces/t00:00:40f0.jpg\n",
      "faces/t00:28:43f1.jpg\n",
      "faces/t00:04:44f0.jpg\n",
      "faces/t00:47:48f1.jpg\n",
      "faces/t00:05:18f0.jpg\n",
      "faces/t00:24:35f0.jpg\n",
      "faces/t00:19:09f0.jpg\n",
      "faces/t00:01:22f0.jpg\n",
      "faces/t00:09:08f0.jpg\n",
      "faces/t00:20:39f0.jpg\n",
      "faces/t00:40:18f0.jpg\n",
      "faces/t00:52:05f0.jpg\n",
      "faces/t00:46:12f0.jpg\n",
      "faces/t00:40:00f0.jpg\n",
      "faces/t00:21:11f0.jpg\n",
      "faces/t00:01:28f0.jpg\n",
      "faces/t00:12:30f0.jpg\n",
      "faces/t00:01:32f0.jpg\n",
      "faces/t00:26:21f0.jpg\n",
      "faces/t00:09:22f0.jpg\n",
      "faces/t00:47:30f0.jpg\n",
      "faces/t00:03:22f0.jpg\n",
      "faces/t00:26:13f0.jpg\n",
      "faces/t00:19:05f0.jpg\n",
      "faces/t00:14:48f0.jpg\n",
      "faces/t00:03:02f0.jpg\n",
      "faces/t00:21:01f0.jpg\n",
      "faces/t00:28:45f0.jpg\n",
      "faces/t00:21:25f0.jpg\n",
      "faces/t00:15:24f0.jpg\n",
      "faces/t00:02:10f1.jpg\n",
      "faces/t00:32:55f0.jpg\n",
      "faces/t00:50:37f0.jpg\n",
      "faces/t00:12:40f0.jpg\n",
      "faces/t00:47:38f0.jpg\n",
      "faces/t00:46:38f0.jpg\n",
      "faces/t00:34:10f0.jpg\n",
      "faces/t00:17:51f0.jpg\n",
      "faces/t00:37:08f0.jpg\n",
      "faces/t00:07:34f0.jpg\n",
      "faces/t00:12:08f0.jpg\n",
      "faces/t00:14:08f0.jpg\n",
      "faces/t00:48:30f0.jpg\n",
      "faces/t00:47:28f0.jpg\n",
      "faces/t00:26:55f0.jpg\n",
      "faces/t00:34:16f0.jpg\n",
      "faces/t00:28:39f0.jpg\n",
      "faces/t00:26:35f0.jpg\n",
      "faces/t00:23:51f0.jpg\n",
      "faces/t00:46:36f0.jpg\n",
      "faces/t00:33:20f0.jpg\n",
      "faces/t00:05:32f0.jpg\n",
      "faces/t00:39:34f0.jpg\n",
      "faces/t00:07:48f0.jpg\n",
      "faces/t00:02:52f0.jpg\n",
      "faces/t00:24:51f0.jpg\n",
      "faces/t00:04:10f0.jpg\n",
      "faces/t00:39:34f1.jpg\n",
      "faces/t00:00:38f0.jpg\n",
      "faces/t00:46:42f0.jpg\n",
      "faces/t00:02:56f0.jpg\n",
      "faces/t00:15:46f0.jpg\n",
      "faces/t00:47:32f1.jpg\n",
      "faces/t00:46:18f1.jpg\n",
      "faces/t00:09:26f0.jpg\n",
      "faces/t00:22:33f0.jpg\n",
      "faces/t00:17:45f0.jpg\n",
      "faces/t00:46:44f0.jpg\n",
      "faces/t00:10:32f0.jpg\n",
      "faces/t00:41:34f0.jpg\n",
      "faces/t00:21:07f0.jpg\n",
      "faces/t00:46:08f0.jpg\n",
      "faces/t00:26:41f0.jpg\n",
      "faces/t00:07:04f0.jpg\n",
      "faces/t00:31:41f0.jpg\n",
      "faces/t00:00:38f2.jpg\n",
      "faces/t00:47:44f0.jpg\n",
      "faces/t00:17:31f1.jpg\n",
      "faces/t00:46:18f0.jpg\n",
      "faces/t00:31:45f0.jpg\n",
      "faces/t00:51:41f1.jpg\n",
      "faces/t00:13:22f0.jpg\n",
      "faces/t00:03:18f0.jpg\n",
      "faces/t00:46:14f0.jpg\n",
      "faces/t00:05:54f0.jpg\n",
      "faces/t00:33:30f0.jpg\n",
      "faces/t00:37:52f0.jpg\n",
      "faces/t00:05:42f0.jpg\n",
      "faces/t00:50:07f0.jpg\n",
      "faces/t00:28:01f0.jpg\n",
      "faces/t00:04:14f1.jpg\n",
      "faces/t00:41:32f1.jpg\n",
      "faces/t00:37:44f0.jpg\n",
      "faces/t00:09:44f0.jpg\n",
      "faces/t00:45:52f0.jpg\n",
      "faces/t00:26:37f0.jpg\n",
      "faces/t00:09:04f0.jpg\n",
      "faces/t00:24:57f0.jpg\n",
      "faces/t00:28:37f0.jpg\n",
      "faces/t00:08:14f0.jpg\n",
      "faces/t00:22:19f0.jpg\n",
      "faces/t00:10:50f0.jpg\n",
      "faces/t00:51:57f0.jpg\n",
      "faces/t00:52:17f0.jpg\n",
      "faces/t00:34:12f0.jpg\n",
      "faces/t00:24:33f0.jpg\n",
      "faces/t00:20:45f0.jpg\n",
      "faces/t00:47:44f1.jpg\n",
      "faces/t00:27:11f0.jpg\n",
      "faces/t00:26:53f0.jpg\n",
      "faces/t00:05:40f0.jpg\n",
      "faces/t00:15:42f0.jpg\n",
      "faces/t00:45:08f0.jpg\n",
      "faces/t00:50:55f0.jpg\n",
      "faces/t00:14:10f1.jpg\n",
      "faces/t00:34:06f0.jpg\n",
      "faces/t00:27:01f0.jpg\n",
      "faces/t00:15:56f0.jpg\n",
      "faces/t00:09:30f0.jpg\n",
      "faces/t00:45:54f0.jpg\n",
      "faces/t00:10:30f0.jpg\n",
      "faces/t00:40:16f0.jpg\n",
      "faces/t00:47:20f0.jpg\n",
      "faces/t00:20:49f0.jpg\n",
      "faces/t00:46:52f0.jpg\n",
      "faces/t00:45:34f0.jpg\n",
      "faces/t00:46:48f0.jpg\n",
      "faces/t00:49:16f0.jpg\n",
      "faces/t00:47:04f0.jpg\n",
      "faces/t00:28:09f0.jpg\n",
      "faces/t00:27:55f0.jpg\n",
      "faces/t00:21:09f0.jpg\n",
      "faces/t00:15:54f0.jpg\n",
      "faces/t00:16:36f0.jpg\n",
      "faces/t00:45:48f0.jpg\n",
      "faces/t00:17:49f0.jpg\n",
      "faces/t00:41:26f0.jpg\n",
      "faces/t00:39:40f1.jpg\n",
      "faces/t00:48:34f0.jpg\n",
      "faces/t00:04:16f0.jpg\n",
      "faces/t00:21:29f0.jpg\n",
      "faces/t00:26:23f0.jpg\n",
      "faces/t00:46:06f0.jpg\n",
      "faces/t00:14:06f0.jpg\n",
      "faces/t00:39:38f1.jpg\n",
      "faces/t00:41:18f0.jpg\n",
      "faces/t00:41:30f0.jpg\n",
      "faces/t00:04:52f1.jpg\n",
      "faces/t00:04:08f0.jpg\n",
      "faces/t00:18:07f0.jpg\n",
      "faces/t00:01:58f0.jpg\n",
      "faces/t00:37:56f0.jpg\n",
      "faces/t00:13:16f0.jpg\n",
      "faces/t00:41:08f0.jpg\n",
      "faces/t00:01:36f0.jpg\n",
      "faces/t00:05:46f0.jpg\n",
      "faces/t00:10:36f0.jpg\n",
      "faces/t00:02:24f0.jpg\n",
      "faces/t00:31:55f0.jpg\n",
      "faces/t00:28:47f1.jpg\n",
      "faces/t00:20:53f0.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces/t00:23:53f0.jpg\n",
      "faces/t00:03:16f0.jpg\n",
      "faces/t00:28:35f0.jpg\n",
      "faces/t00:40:48f0.jpg\n",
      "faces/t00:40:40f0.jpg\n",
      "faces/t00:17:53f0.jpg\n",
      "faces/t00:05:38f0.jpg\n",
      "faces/t00:47:34f1.jpg\n",
      "faces/t00:04:22f1.jpg\n",
      "faces/t00:17:41f0.jpg\n",
      "faces/t00:34:04f0.jpg\n",
      "faces/t00:39:36f1.jpg\n",
      "faces/t00:25:51f0.jpg\n",
      "faces/t00:04:36f0.jpg\n",
      "running all images through NN model ...\n",
      "faces/t00:05:28f0.jpg\n",
      "faces/t00:27:47f0.jpg\n",
      "faces/t00:22:23f0.jpg\n",
      "faces/t00:50:05f0.jpg\n",
      "faces/t00:14:50f1.jpg\n",
      "faces/t00:46:50f0.jpg\n",
      "faces/t00:45:46f0.jpg\n",
      "faces/t00:40:20f0.jpg\n",
      "faces/t00:24:47f0.jpg\n",
      "faces/t00:37:46f0.jpg\n",
      "faces/t00:37:16f0.jpg\n",
      "faces/t00:01:48f0.jpg\n",
      "faces/t00:45:32f0.jpg\n",
      "faces/t00:47:10f0.jpg\n",
      "faces/t00:33:58f0.jpg\n",
      "faces/t00:41:24f0.jpg\n",
      "faces/t00:47:46f0.jpg\n",
      "faces/t00:04:16f1.jpg\n",
      "faces/t00:21:03f0.jpg\n",
      "faces/t00:28:31f0.jpg\n",
      "faces/t00:45:06f0.jpg\n",
      "faces/t00:17:47f0.jpg\n",
      "faces/t00:40:32f0.jpg\n",
      "faces/t00:28:05f0.jpg\n",
      "faces/t00:33:26f1.jpg\n",
      "faces/t00:33:22f0.jpg\n",
      "faces/t00:12:34f0.jpg\n",
      "faces/t00:52:09f0.jpg\n",
      "faces/t00:32:13f0.jpg\n",
      "faces/t00:08:42f0.jpg\n",
      "faces/t00:04:02f0.jpg\n",
      "faces/t00:49:08f1.jpg\n",
      "faces/t00:49:08f0.jpg\n",
      "faces/t00:18:51f0.jpg\n",
      "faces/t00:34:18f0.jpg\n",
      "faces/t00:48:58f0.jpg\n",
      "faces/t00:21:15f0.jpg\n",
      "faces/t00:47:00f0.jpg\n",
      "faces/t00:08:56f0.jpg\n",
      "faces/t00:39:40f0.jpg\n",
      "faces/t00:45:50f0.jpg\n",
      "faces/t00:32:11f0.jpg\n",
      "faces/t00:13:20f0.jpg\n",
      "faces/t00:18:01f0.jpg\n",
      "faces/t00:17:57f0.jpg\n",
      "faces/t00:00:42f0.jpg\n",
      "faces/t00:04:52f0.jpg\n",
      "faces/t00:28:15f0.jpg\n",
      "faces/t00:45:30f0.jpg\n",
      "faces/t00:09:08f1.jpg\n",
      "faces/t00:28:53f0.jpg\n",
      "faces/t00:18:37f0.jpg\n",
      "faces/t00:28:03f0.jpg\n",
      "faces/t00:07:40f0.jpg\n",
      "faces/t00:12:52f0.jpg\n",
      "faces/t00:10:26f0.jpg\n",
      "faces/t00:51:31f0.jpg\n",
      "faces/t00:23:35f0.jpg\n",
      "faces/t00:48:12f0.jpg\n",
      "faces/t00:17:55f0.jpg\n",
      "faces/t00:25:19f0.jpg\n",
      "faces/t00:14:12f1.jpg\n",
      "faces/t00:25:11f0.jpg\n",
      "faces/t00:02:08f0.jpg\n",
      "faces/t00:09:12f0.jpg\n",
      "faces/t00:45:58f0.jpg\n",
      "faces/t00:02:22f0.jpg\n",
      "faces/t00:26:01f0.jpg\n",
      "faces/t00:24:07f0.jpg\n",
      "faces/t00:34:52f0.jpg\n",
      "faces/t00:09:06f1.jpg\n",
      "faces/t00:39:58f0.jpg\n",
      "faces/t00:45:20f0.jpg\n",
      "faces/t00:28:55f0.jpg\n",
      "faces/t00:36:58f0.jpg\n",
      "faces/t00:18:35f0.jpg\n",
      "faces/t00:18:27f0.jpg\n",
      "faces/t00:21:29f1.jpg\n",
      "faces/t00:26:59f0.jpg\n",
      "faces/t00:28:49f1.jpg\n",
      "faces/t00:09:14f0.jpg\n",
      "faces/t00:47:40f0.jpg\n",
      "faces/t00:12:28f0.jpg\n",
      "faces/t00:28:45f1.jpg\n",
      "faces/t00:28:21f0.jpg\n",
      "faces/t00:13:14f0.jpg\n",
      "faces/t00:40:02f0.jpg\n",
      "faces/t00:30:13f0.jpg\n",
      "faces/t00:12:50f0.jpg\n",
      "faces/t00:45:06f2.jpg\n",
      "faces/t00:40:14f0.jpg\n",
      "faces/t00:10:22f0.jpg\n",
      "faces/t00:23:59f0.jpg\n",
      "faces/t00:17:31f0.jpg\n",
      "faces/t00:04:34f0.jpg\n",
      "faces/t00:25:21f0.jpg\n",
      "faces/t00:11:54f0.jpg\n",
      "faces/t00:10:52f0.jpg\n",
      "faces/t00:45:10f0.jpg\n",
      "faces/t00:26:43f0.jpg\n",
      "faces/t00:04:24f1.jpg\n",
      "faces/t00:37:10f1.jpg\n",
      "faces/t00:22:27f0.jpg\n",
      "faces/t00:40:30f0.jpg\n",
      "faces/t00:17:37f0.jpg\n",
      "faces/t00:33:17f0.jpg\n",
      "faces/t00:26:39f0.jpg\n",
      "faces/t00:04:50f0.jpg\n",
      "faces/t00:47:50f0.jpg\n",
      "faces/t00:11:42f0.jpg\n",
      "faces/t00:00:34f0.jpg\n",
      "faces/t00:11:26f0.jpg\n",
      "faces/t00:26:45f0.jpg\n",
      "faces/t00:25:09f0.jpg\n",
      "faces/t00:05:48f0.jpg\n",
      "faces/t00:48:48f1.jpg\n",
      "faces/t00:01:30f0.jpg\n",
      "faces/t00:51:53f0.jpg\n",
      "faces/t00:09:20f0.jpg\n",
      "faces/t00:45:54f1.jpg\n",
      "faces/t00:30:57f0.jpg\n",
      "faces/t00:28:51f1.jpg\n",
      "faces/t00:32:15f0.jpg\n",
      "faces/t00:34:02f1.jpg\n",
      "faces/t00:09:00f0.jpg\n",
      "faces/t00:47:18f0.jpg\n",
      "faces/t00:49:12f0.jpg\n",
      "faces/t00:10:56f0.jpg\n",
      "faces/t00:13:10f0.jpg\n",
      "faces/t00:33:52f0.jpg\n",
      "faces/t00:20:57f0.jpg\n",
      "faces/t00:14:36f0.jpg\n",
      "faces/t00:48:16f0.jpg\n",
      "faces/t00:39:48f0.jpg\n",
      "faces/t00:11:48f0.jpg\n",
      "faces/t00:27:51f0.jpg\n",
      "faces/t00:37:18f0.jpg\n",
      "faces/t00:22:25f0.jpg\n",
      "faces/t00:47:22f0.jpg\n",
      "faces/t00:08:20f0.jpg\n",
      "faces/t00:46:16f0.jpg\n",
      "faces/t00:16:00f0.jpg\n",
      "faces/t00:11:58f0.jpg\n",
      "faces/t00:12:02f0.jpg\n",
      "faces/t00:14:02f0.jpg\n",
      "faces/t00:21:51f0.jpg\n",
      "faces/t00:40:28f0.jpg\n",
      "faces/t00:27:07f0.jpg\n",
      "faces/t00:48:46f0.jpg\n",
      "faces/t00:19:49f0.jpg\n",
      "faces/t00:48:36f0.jpg\n",
      "faces/t00:18:11f0.jpg\n",
      "faces/t00:26:31f0.jpg\n",
      "faces/t00:33:13f0.jpg\n",
      "faces/t00:30:59f0.jpg\n",
      "faces/t00:40:52f0.jpg\n",
      "faces/t00:46:12f1.jpg\n",
      "faces/t00:46:32f0.jpg\n",
      "faces/t00:13:18f0.jpg\n",
      "faces/t00:26:07f0.jpg\n",
      "faces/t00:37:42f0.jpg\n",
      "faces/t00:18:25f0.jpg\n",
      "faces/t00:48:54f0.jpg\n",
      "faces/t00:49:04f0.jpg\n",
      "faces/t00:21:13f0.jpg\n",
      "faces/t00:24:05f0.jpg\n",
      "faces/t00:13:56f0.jpg\n",
      "faces/t00:37:12f0.jpg\n",
      "faces/t00:21:37f0.jpg\n",
      "faces/t00:37:04f0.jpg\n",
      "faces/t00:34:00f0.jpg\n",
      "faces/t00:49:18f0.jpg\n",
      "faces/t00:19:51f0.jpg\n",
      "faces/t00:50:03f0.jpg\n",
      "faces/t00:47:02f0.jpg\n",
      "faces/t00:18:13f0.jpg\n",
      "faces/t00:18:33f0.jpg\n",
      "faces/t00:27:05f0.jpg\n",
      "faces/t00:25:53f0.jpg\n",
      "faces/t00:10:48f1.jpg\n",
      "faces/t00:11:40f0.jpg\n",
      "faces/t00:25:05f0.jpg\n",
      "faces/t00:27:59f0.jpg\n",
      "faces/t00:47:24f0.jpg\n",
      "faces/t00:07:06f0.jpg\n",
      "faces/t00:19:01f0.jpg\n",
      "faces/t00:28:27f0.jpg\n",
      "faces/t00:51:39f1.jpg\n",
      "faces/t00:25:07f0.jpg\n",
      "faces/t00:46:56f0.jpg\n",
      "faces/t00:27:57f0.jpg\n",
      "faces/t00:48:28f0.jpg\n",
      "faces/t00:32:07f0.jpg\n",
      "faces/t00:48:40f0.jpg\n",
      "faces/t00:51:59f0.jpg\n",
      "faces/t00:48:56f0.jpg\n",
      "faces/t00:25:13f1.jpg\n",
      "faces/t00:15:10f0.jpg\n",
      "faces/t00:04:04f0.jpg\n",
      "faces/t00:51:37f0.jpg\n",
      "faces/t00:19:03f1.jpg\n",
      "faces/t00:46:04f0.jpg\n",
      "faces/t00:52:19f0.jpg\n",
      "faces/t00:40:54f0.jpg\n",
      "faces/t00:49:10f1.jpg\n",
      "faces/t00:47:08f0.jpg\n",
      "faces/t00:15:24f1.jpg\n",
      "faces/t00:24:49f0.jpg\n",
      "faces/t00:18:45f0.jpg\n",
      "faces/t00:39:02f0.jpg\n",
      "faces/t00:07:02f0.jpg\n",
      "faces/t00:33:54f0.jpg\n",
      "faces/t00:24:21f0.jpg\n",
      "faces/t00:14:00f0.jpg\n",
      "faces/t00:34:14f0.jpg\n",
      "faces/t00:04:22f0.jpg\n",
      "faces/t00:06:52f0.jpg\n",
      "faces/t00:26:57f0.jpg\n",
      "faces/t00:04:48f0.jpg\n",
      "faces/t00:39:04f0.jpg\n",
      "faces/t00:14:04f0.jpg\n",
      "faces/t00:48:26f0.jpg\n",
      "faces/t00:45:40f0.jpg\n",
      "faces/t00:24:03f0.jpg\n",
      "faces/t00:15:58f0.jpg\n",
      "faces/t00:05:16f0.jpg\n",
      "faces/t00:24:19f0.jpg\n",
      "faces/t00:45:38f0.jpg\n",
      "faces/t00:27:21f0.jpg\n",
      "faces/t00:04:26f0.jpg\n",
      "faces/t00:09:42f0.jpg\n",
      "faces/t00:01:46f0.jpg\n",
      "faces/t00:11:30f0.jpg\n",
      "faces/t00:13:20f1.jpg\n",
      "faces/t00:05:36f0.jpg\n",
      "faces/t00:48:32f0.jpg\n",
      "faces/t00:12:54f0.jpg\n",
      "faces/t00:41:04f0.jpg\n",
      "faces/t00:17:29f0.jpg\n",
      "faces/t00:27:09f0.jpg\n",
      "faces/t00:47:14f0.jpg\n",
      "faces/t00:51:41f0.jpg\n",
      "faces/t00:46:40f0.jpg\n",
      "faces/t00:01:18f0.jpg\n",
      "faces/t00:00:32f1.jpg\n",
      "faces/t00:05:26f0.jpg\n",
      "faces/t00:09:40f0.jpg\n",
      "faces/t00:21:31f0.jpg\n",
      "faces/t00:52:01f0.jpg\n",
      "faces/t00:09:38f0.jpg\n",
      "faces/t00:37:06f0.jpg\n",
      "faces/t00:00:36f0.jpg\n",
      "faces/t00:41:28f0.jpg\n",
      "faces/t00:48:10f0.jpg\n",
      "faces/t00:04:30f0.jpg\n",
      "faces/t00:34:00f1.jpg\n",
      "faces/t00:50:57f0.jpg\n",
      "faces/t00:02:18f0.jpg\n",
      "faces/t00:19:47f0.jpg\n",
      "faces/t00:18:59f0.jpg\n",
      "faces/t00:39:36f0.jpg\n",
      "faces/t00:24:23f0.jpg\n",
      "faces/t00:04:42f0.jpg\n",
      "faces/t00:20:51f0.jpg\n",
      "faces/t00:40:42f0.jpg\n",
      "faces/t00:26:15f0.jpg\n",
      "faces/t00:04:18f0.jpg\n",
      "faces/t00:18:43f0.jpg\n",
      "faces/t00:09:06f0.jpg\n",
      "faces/t00:05:50f0.jpg\n",
      "faces/t00:26:47f0.jpg\n",
      "faces/t00:34:22f0.jpg\n",
      "faces/t00:00:44f0.jpg\n",
      "faces/t00:05:22f0.jpg\n",
      "faces/t00:10:34f0.jpg\n",
      "faces/t00:34:20f0.jpg\n",
      "faces/t00:46:30f0.jpg\n",
      "faces/t00:20:59f0.jpg\n",
      "faces/t00:05:14f0.jpg\n",
      "faces/t00:05:56f0.jpg\n",
      "faces/t00:12:42f0.jpg\n",
      "faces/t00:08:54f0.jpg\n",
      "faces/t00:28:51f0.jpg\n",
      "faces/t00:18:09f0.jpg\n",
      "faces/t00:38:56f0.jpg\n",
      "faces/t00:25:57f0.jpg\n",
      "faces/t00:01:38f0.jpg\n",
      "faces/t00:47:42f1.jpg\n",
      "faces/t00:17:35f0.jpg\n",
      "faces/t00:40:12f0.jpg\n",
      "faces/t00:17:45f1.jpg\n",
      "faces/t00:33:56f0.jpg\n",
      "faces/t00:45:56f0.jpg\n",
      "faces/t00:07:38f0.jpg\n",
      "faces/t00:21:35f0.jpg\n",
      "faces/t00:45:36f0.jpg\n",
      "faces/t00:31:39f0.jpg\n",
      "faces/t00:28:47f0.jpg\n",
      "faces/t00:05:24f0.jpg\n",
      "faces/t00:25:55f0.jpg\n",
      "faces/t00:32:17f0.jpg\n",
      "faces/t00:28:19f0.jpg\n",
      "faces/t00:15:34f0.jpg\n",
      "faces/t00:18:15f0.jpg\n",
      "faces/t00:00:38f1.jpg\n",
      "faces/t00:47:38f1.jpg\n",
      "faces/t00:46:22f0.jpg\n",
      "faces/t00:18:31f0.jpg\n",
      "faces/t00:33:11f0.jpg\n",
      "faces/t00:12:58f0.jpg\n",
      "faces/t00:07:36f0.jpg\n",
      "faces/t00:15:08f0.jpg\n",
      "faces/t00:01:44f0.jpg\n",
      "faces/t00:26:51f0.jpg\n",
      "faces/t00:28:33f0.jpg\n",
      "faces/t00:26:05f0.jpg\n",
      "faces/t00:33:26f0.jpg\n",
      "faces/t00:48:52f0.jpg\n",
      "faces/t00:47:06f0.jpg\n",
      "faces/t00:08:44f0.jpg\n",
      "faces/t00:18:19f0.jpg\n",
      "faces/t00:01:20f0.jpg\n",
      "faces/t00:01:34f0.jpg\n",
      "faces/t00:04:20f0.jpg\n",
      "faces/t00:34:04f1.jpg\n",
      "faces/t00:39:00f0.jpg\n",
      "faces/t00:26:17f0.jpg\n",
      "faces/t00:12:26f0.jpg\n",
      "faces/t00:17:33f0.jpg\n",
      "faces/t00:33:50f0.jpg\n",
      "faces/t00:47:12f0.jpg\n",
      "faces/t00:28:43f0.jpg\n",
      "faces/t00:25:17f0.jpg\n",
      "faces/t00:14:12f0.jpg\n",
      "faces/t00:01:24f0.jpg\n",
      "faces/t00:10:28f0.jpg\n",
      "faces/t00:28:49f0.jpg\n",
      "faces/t00:17:43f0.jpg\n",
      "faces/t00:48:38f0.jpg\n",
      "faces/t00:37:02f0.jpg\n",
      "faces/t00:21:05f0.jpg\n",
      "faces/t00:11:14f0.jpg\n",
      "faces/t00:49:14f0.jpg\n",
      "faces/t00:28:41f1.jpg\n",
      "faces/t00:46:08f1.jpg\n",
      "faces/t00:09:18f0.jpg\n",
      "faces/t00:12:32f0.jpg\n",
      "faces/t00:13:58f0.jpg\n",
      "faces/t00:24:31f0.jpg\n",
      "faces/t00:34:02f0.jpg\n",
      "faces/t00:44:28f0.jpg\n",
      "faces/t00:07:00f0.jpg\n",
      "faces/t00:41:14f0.jpg\n",
      "faces/t00:46:54f0.jpg\n",
      "faces/t00:02:02f0.jpg\n",
      "faces/t00:28:25f0.jpg\n",
      "faces/t00:18:39f0.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces/t00:15:38f0.jpg\n",
      "faces/t00:14:48f1.jpg\n",
      "faces/t00:26:49f0.jpg\n",
      "faces/t00:09:36f0.jpg\n",
      "faces/t00:06:54f0.jpg\n",
      "faces/t00:49:12f1.jpg\n",
      "faces/t00:04:18f1.jpg\n",
      "faces/t00:26:27f0.jpg\n",
      "faces/t00:25:15f1.jpg\n",
      "faces/t00:18:05f0.jpg\n",
      "faces/t00:48:48f0.jpg\n",
      "faces/t00:46:24f0.jpg\n",
      "faces/t00:51:55f0.jpg\n",
      "faces/t00:11:52f0.jpg\n",
      "faces/t00:15:30f0.jpg\n",
      "faces/t00:37:48f0.jpg\n",
      "faces/t00:23:37f0.jpg\n",
      "faces/t00:09:16f0.jpg\n",
      "faces/t00:26:29f0.jpg\n",
      "faces/t00:49:00f0.jpg\n",
      "faces/t00:09:02f0.jpg\n",
      "faces/t00:03:20f0.jpg\n",
      "faces/t00:04:40f0.jpg\n",
      "faces/t00:11:06f0.jpg\n",
      "faces/t00:17:59f0.jpg\n",
      "faces/t00:20:55f0.jpg\n",
      "faces/t00:47:48f0.jpg\n",
      "faces/t00:04:50f1.jpg\n",
      "faces/t00:48:22f0.jpg\n",
      "faces/t00:26:09f0.jpg\n",
      "faces/t00:10:48f0.jpg\n",
      "faces/t00:23:49f0.jpg\n",
      "faces/t00:25:13f0.jpg\n",
      "faces/t00:13:52f0.jpg\n",
      "faces/t00:45:18f0.jpg\n",
      "faces/t00:19:55f0.jpg\n",
      "faces/t00:27:53f0.jpg\n",
      "faces/t00:52:19f1.jpg\n",
      "faces/t00:33:15f1.jpg\n",
      "faces/t00:45:44f0.jpg\n",
      "faces/t00:04:06f0.jpg\n",
      "faces/t00:46:00f0.jpg\n",
      "faces/t00:47:46f1.jpg\n",
      "faces/t00:12:24f0.jpg\n",
      "faces/t00:09:28f0.jpg\n",
      "faces/t00:25:59f0.jpg\n",
      "faces/t00:28:41f0.jpg\n",
      "faces/t00:07:46f0.jpg\n",
      "faces/t00:40:24f0.jpg\n",
      "faces/t00:17:39f0.jpg\n",
      "faces/t00:18:03f0.jpg\n",
      "faces/t00:11:04f0.jpg\n",
      "faces/t00:21:27f0.jpg\n",
      "faces/t00:37:14f0.jpg\n",
      "faces/t00:18:29f0.jpg\n",
      "faces/t00:28:55f1.jpg\n",
      "faces/t00:00:04f0.jpg\n",
      "faces/t00:49:16f1.jpg\n",
      "faces/t00:26:11f0.jpg\n",
      "faces/t00:49:10f0.jpg\n",
      "faces/t00:18:41f0.jpg\n",
      "faces/t00:47:36f1.jpg\n",
      "faces/t00:06:36f0.jpg\n",
      "faces/t00:43:16f0.jpg\n",
      "faces/t00:46:10f0.jpg\n",
      "faces/t00:25:17f1.jpg\n",
      "faces/t00:49:22f0.jpg\n",
      "faces/t00:14:50f0.jpg\n",
      "faces/t00:24:37f0.jpg\n",
      "faces/t00:20:37f0.jpg\n",
      "faces/t00:47:32f0.jpg\n",
      "faces/t00:47:26f0.jpg\n",
      "faces/t00:51:39f0.jpg\n",
      "faces/t00:01:26f0.jpg\n",
      "faces/t00:48:18f0.jpg\n",
      "faces/t00:21:33f0.jpg\n",
      "faces/t00:37:00f0.jpg\n",
      "faces/t00:14:26f0.jpg\n",
      "faces/t00:39:38f0.jpg\n",
      "faces/t00:16:02f0.jpg\n",
      "faces/t00:00:36f2.jpg\n",
      "faces/t00:04:32f0.jpg\n",
      "faces/t00:14:10f0.jpg\n",
      "faces/t00:28:11f0.jpg\n",
      "faces/t00:07:42f0.jpg\n",
      "faces/t00:33:32f0.jpg\n",
      "faces/t00:03:00f0.jpg\n",
      "faces/t00:46:20f1.jpg\n",
      "faces/t00:28:17f0.jpg\n",
      "faces/t00:19:45f0.jpg\n",
      "faces/t00:37:40f0.jpg\n",
      "faces/t00:46:34f0.jpg\n",
      "faces/t00:46:10f1.jpg\n",
      "faces/t00:04:26f1.jpg\n",
      "faces/t00:08:58f0.jpg\n",
      "faces/t00:25:15f0.jpg\n",
      "faces/t00:49:20f0.jpg\n",
      "faces/t00:49:02f0.jpg\n",
      "faces/t00:48:50f0.jpg\n",
      "faces/t00:27:03f0.jpg\n",
      "faces/t00:05:30f0.jpg\n",
      "faces/t00:47:42f0.jpg\n",
      "faces/t00:32:09f0.jpg\n",
      "faces/t00:13:06f0.jpg\n",
      "faces/t00:21:39f0.jpg\n",
      "faces/t00:18:17f0.jpg\n",
      "faces/t00:26:25f0.jpg\n",
      "faces/t00:05:52f0.jpg\n",
      "faces/t00:07:04f1.jpg\n",
      "faces/t00:19:43f0.jpg\n",
      "faces/t00:20:01f0.jpg\n",
      "faces/t00:02:18f1.jpg\n",
      "faces/t00:27:49f0.jpg\n",
      "faces/t00:41:06f0.jpg\n",
      "faces/t00:09:10f1.jpg\n",
      "faces/t00:09:46f0.jpg\n",
      "faces/t00:24:25f0.jpg\n",
      "faces/t00:48:24f0.jpg\n",
      "faces/t00:18:21f0.jpg\n",
      "faces/t00:45:58f1.jpg\n",
      "faces/t00:45:56f1.jpg\n",
      "faces/t00:04:38f0.jpg\n",
      "faces/t00:51:13f0.jpg\n",
      "faces/t00:07:50f0.jpg\n",
      "faces/t00:46:46f0.jpg\n",
      "faces/t00:26:03f0.jpg\n",
      "faces/t00:02:48f0.jpg\n",
      "faces/t00:03:04f0.jpg\n",
      "faces/t00:00:36f1.jpg\n",
      "faces/t00:11:50f0.jpg\n",
      "faces/t00:37:50f0.jpg\n",
      "faces/t00:37:54f0.jpg\n",
      "faces/t00:39:08f0.jpg\n",
      "faces/t00:48:50f1.jpg\n",
      "faces/t00:27:23f0.jpg\n",
      "faces/t00:48:46f1.jpg\n",
      "faces/t00:10:54f0.jpg\n",
      "faces/t00:06:58f0.jpg\n",
      "faces/t00:26:33f0.jpg\n",
      "faces/t00:46:20f0.jpg\n",
      "faces/t00:50:39f0.jpg\n",
      "faces/t00:11:08f0.jpg\n",
      "faces/t00:10:46f0.jpg\n",
      "faces/t00:47:16f0.jpg\n",
      "faces/t00:40:26f0.jpg\n",
      "faces/t00:18:23f0.jpg\n",
      "faces/t00:28:07f0.jpg\n",
      "faces/t00:05:44f0.jpg\n",
      "faces/t00:04:24f0.jpg\n",
      "faces/t00:28:29f0.jpg\n",
      "faces/t00:19:07f0.jpg\n",
      "faces/t00:31:21f0.jpg\n",
      "faces/t00:09:48f0.jpg\n",
      "faces/t00:06:56f0.jpg\n",
      "faces/t00:34:08f0.jpg\n",
      "faces/t00:21:49f0.jpg\n",
      "faces/t00:43:14f0.jpg\n",
      "faces/t00:18:47f0.jpg\n",
      "faces/t00:11:16f0.jpg\n",
      "faces/t00:02:58f0.jpg\n",
      "faces/t00:45:42f0.jpg\n",
      "faces/t00:46:28f0.jpg\n",
      "faces/t00:37:10f0.jpg\n",
      "faces/t00:28:23f0.jpg\n",
      "faces/t00:18:49f0.jpg\n",
      "faces/t00:37:38f0.jpg\n",
      "faces/t00:10:38f0.jpg\n",
      "faces/t00:33:15f0.jpg\n",
      "faces/t00:04:20f1.jpg\n",
      "faces/t00:38:58f0.jpg\n",
      "faces/t00:47:52f0.jpg\n",
      "faces/t00:19:59f0.jpg\n",
      "faces/t00:13:08f0.jpg\n",
      "faces/t00:41:32f0.jpg\n",
      "faces/t00:46:58f0.jpg\n",
      "faces/t00:47:36f0.jpg\n",
      "faces/t00:02:10f0.jpg\n",
      "faces/t00:04:46f0.jpg\n",
      "faces/t00:09:34f0.jpg\n",
      "faces/t00:20:29f0.jpg\n",
      "faces/t00:46:02f0.jpg\n",
      "faces/t00:25:11f1.jpg\n",
      "faces/t00:31:43f0.jpg\n",
      "faces/t00:05:20f0.jpg\n",
      "faces/t00:47:30f1.jpg\n",
      "faces/t00:37:58f0.jpg\n",
      "faces/t00:28:53f1.jpg\n",
      "faces/t00:09:32f0.jpg\n",
      "faces/t00:43:12f0.jpg\n",
      "faces/t00:28:13f0.jpg\n",
      "faces/t00:01:22f0.jpg\n",
      "faces/t00:52:05f0.jpg\n",
      "faces/t00:26:21f0.jpg\n",
      "faces/t00:03:22f0.jpg\n",
      "faces/t00:28:45f0.jpg\n",
      "faces/t00:15:24f0.jpg\n",
      "faces/t00:47:38f0.jpg\n",
      "faces/t00:14:08f0.jpg\n",
      "faces/t00:47:28f0.jpg\n",
      "faces/t00:46:26f0.jpg\n",
      "faces/t00:23:51f0.jpg\n",
      "faces/t00:39:34f0.jpg\n",
      "faces/t00:24:51f0.jpg\n",
      "faces/t00:04:10f0.jpg\n",
      "faces/t00:46:42f0.jpg\n",
      "faces/t00:46:18f1.jpg\n",
      "faces/t00:46:44f0.jpg\n",
      "faces/t00:07:04f0.jpg\n",
      "faces/t00:47:44f0.jpg\n",
      "faces/t00:03:18f0.jpg\n",
      "faces/t00:46:14f0.jpg\n",
      "faces/t00:05:54f0.jpg\n",
      "faces/t00:33:30f0.jpg\n",
      "faces/t00:04:14f1.jpg\n",
      "faces/t00:45:52f0.jpg\n",
      "faces/t00:09:04f0.jpg\n",
      "faces/t00:08:14f0.jpg\n",
      "faces/t00:52:17f0.jpg\n",
      "faces/t00:47:44f1.jpg\n",
      "faces/t00:11:38f0.jpg\n",
      "faces/t00:39:06f0.jpg\n",
      "faces/t00:02:20f0.jpg\n",
      "faces/t00:48:20f0.jpg\n",
      "faces/t00:17:27f0.jpg\n",
      "faces/t00:49:06f0.jpg\n",
      "faces/t00:34:54f0.jpg\n",
      "faces/t00:19:03f0.jpg\n",
      "faces/t00:02:54f0.jpg\n",
      "faces/t00:09:24f0.jpg\n",
      "faces/t00:41:16f0.jpg\n",
      "faces/t00:12:20f0.jpg\n",
      "faces/t00:41:36f0.jpg\n",
      "faces/t00:12:56f0.jpg\n",
      "faces/t00:21:31f1.jpg\n",
      "faces/t00:40:50f0.jpg\n",
      "faces/t00:49:14f1.jpg\n",
      "faces/t00:45:06f1.jpg\n",
      "faces/t00:04:12f0.jpg\n",
      "faces/t00:10:24f0.jpg\n",
      "faces/t00:00:40f0.jpg\n",
      "faces/t00:04:44f0.jpg\n",
      "faces/t00:05:18f0.jpg\n",
      "faces/t00:19:09f0.jpg\n",
      "faces/t00:09:08f0.jpg\n",
      "faces/t00:46:12f0.jpg\n",
      "faces/t00:12:30f0.jpg\n",
      "faces/t00:09:22f0.jpg\n",
      "faces/t00:19:05f0.jpg\n",
      "faces/t00:03:02f0.jpg\n",
      "faces/t00:50:37f0.jpg\n",
      "faces/t00:34:10f0.jpg\n",
      "faces/t00:07:34f0.jpg\n",
      "faces/t00:02:50f0.jpg\n",
      "faces/t00:28:39f0.jpg\n",
      "faces/t00:33:20f0.jpg\n",
      "faces/t00:02:52f0.jpg\n",
      "faces/t00:15:46f0.jpg\n",
      "faces/t00:22:33f0.jpg\n",
      "faces/t00:00:38f2.jpg\n",
      "faces/t00:31:45f0.jpg\n",
      "faces/t00:28:01f0.jpg\n",
      "faces/t00:09:44f0.jpg\n",
      "faces/t00:24:57f0.jpg\n",
      "faces/t00:10:50f0.jpg\n",
      "faces/t00:20:45f0.jpg\n",
      "faces/t00:05:40f0.jpg\n",
      "faces/t00:45:08f0.jpg\n",
      "faces/t00:04:14f0.jpg\n",
      "faces/t00:08:16f0.jpg\n",
      "faces/t00:07:44f0.jpg\n",
      "faces/t00:19:41f0.jpg\n",
      "faces/t00:00:32f0.jpg\n",
      "faces/t00:26:19f0.jpg\n",
      "faces/t00:05:34f0.jpg\n",
      "faces/t00:19:53f0.jpg\n",
      "faces/t00:13:12f0.jpg\n",
      "faces/t00:48:14f0.jpg\n",
      "faces/t00:09:10f0.jpg\n",
      "faces/t00:20:47f0.jpg\n",
      "faces/t00:47:40f1.jpg\n",
      "faces/t00:47:34f0.jpg\n",
      "faces/t00:28:43f1.jpg\n",
      "faces/t00:47:48f1.jpg\n",
      "faces/t00:24:35f0.jpg\n",
      "faces/t00:20:39f0.jpg\n",
      "faces/t00:40:00f0.jpg\n",
      "faces/t00:01:32f0.jpg\n",
      "faces/t00:26:13f0.jpg\n",
      "faces/t00:21:01f0.jpg\n",
      "faces/t00:21:25f0.jpg\n",
      "faces/t00:02:10f1.jpg\n",
      "faces/t00:12:40f0.jpg\n",
      "faces/t00:17:51f0.jpg\n",
      "faces/t00:37:08f0.jpg\n",
      "faces/t00:48:30f0.jpg\n",
      "faces/t00:04:28f0.jpg\n",
      "faces/t00:26:35f0.jpg\n",
      "faces/t00:46:36f0.jpg\n",
      "faces/t00:05:32f0.jpg\n",
      "faces/t00:39:34f1.jpg\n",
      "faces/t00:09:26f0.jpg\n",
      "faces/t00:10:32f0.jpg\n",
      "faces/t00:41:34f0.jpg\n",
      "faces/t00:21:07f0.jpg\n",
      "faces/t00:46:08f0.jpg\n",
      "faces/t00:26:41f0.jpg\n",
      "faces/t00:31:41f0.jpg\n",
      "faces/t00:17:31f1.jpg\n",
      "faces/t00:13:22f0.jpg\n",
      "faces/t00:05:42f0.jpg\n",
      "faces/t00:50:07f0.jpg\n",
      "faces/t00:37:44f0.jpg\n",
      "faces/t00:28:37f0.jpg\n",
      "faces/t00:51:57f0.jpg\n",
      "faces/t00:26:53f0.jpg\n",
      "faces/t00:40:18f0.jpg\n",
      "faces/t00:21:11f0.jpg\n",
      "faces/t00:01:28f0.jpg\n",
      "faces/t00:47:30f0.jpg\n",
      "faces/t00:14:48f0.jpg\n",
      "faces/t00:32:55f0.jpg\n",
      "faces/t00:46:38f0.jpg\n",
      "faces/t00:12:08f0.jpg\n",
      "faces/t00:26:55f0.jpg\n",
      "faces/t00:31:47f0.jpg\n",
      "faces/t00:34:16f0.jpg\n",
      "faces/t00:07:48f0.jpg\n",
      "faces/t00:00:38f0.jpg\n",
      "faces/t00:02:56f0.jpg\n",
      "faces/t00:47:32f1.jpg\n",
      "faces/t00:17:45f0.jpg\n",
      "faces/t00:46:18f0.jpg\n",
      "faces/t00:51:41f1.jpg\n",
      "faces/t00:37:52f0.jpg\n",
      "faces/t00:41:32f1.jpg\n",
      "faces/t00:26:37f0.jpg\n",
      "faces/t00:22:19f0.jpg\n",
      "faces/t00:34:12f0.jpg\n",
      "faces/t00:24:33f0.jpg\n",
      "faces/t00:27:11f0.jpg\n",
      "faces/t00:15:42f0.jpg\n",
      "faces/t00:50:55f0.jpg\n",
      "faces/t00:14:10f1.jpg\n",
      "faces/t00:34:06f0.jpg\n",
      "faces/t00:15:56f0.jpg\n",
      "faces/t00:45:54f0.jpg\n",
      "faces/t00:40:16f0.jpg\n",
      "faces/t00:20:49f0.jpg\n",
      "faces/t00:45:34f0.jpg\n",
      "faces/t00:47:04f0.jpg\n",
      "faces/t00:27:55f0.jpg\n",
      "faces/t00:15:54f0.jpg\n",
      "faces/t00:16:36f0.jpg\n",
      "faces/t00:17:49f0.jpg\n",
      "faces/t00:39:40f1.jpg\n",
      "faces/t00:04:16f0.jpg\n",
      "faces/t00:46:06f0.jpg\n",
      "faces/t00:39:38f1.jpg\n",
      "faces/t00:04:52f1.jpg\n",
      "faces/t00:01:36f0.jpg\n",
      "faces/t00:05:46f0.jpg\n",
      "faces/t00:10:36f0.jpg\n",
      "faces/t00:02:24f0.jpg\n",
      "faces/t00:27:01f0.jpg\n",
      "faces/t00:09:30f0.jpg\n",
      "faces/t00:10:30f0.jpg\n",
      "faces/t00:47:20f0.jpg\n",
      "faces/t00:46:52f0.jpg\n",
      "faces/t00:46:48f0.jpg\n",
      "faces/t00:49:16f0.jpg\n",
      "faces/t00:28:09f0.jpg\n",
      "faces/t00:21:09f0.jpg\n",
      "faces/t00:45:48f0.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces/t00:41:26f0.jpg\n",
      "faces/t00:48:34f0.jpg\n",
      "faces/t00:21:29f0.jpg\n",
      "faces/t00:26:23f0.jpg\n",
      "faces/t00:14:06f0.jpg\n",
      "faces/t00:41:18f0.jpg\n",
      "faces/t00:41:30f0.jpg\n",
      "faces/t00:04:08f0.jpg\n",
      "faces/t00:18:07f0.jpg\n",
      "faces/t00:01:58f0.jpg\n",
      "faces/t00:37:56f0.jpg\n",
      "faces/t00:13:16f0.jpg\n",
      "faces/t00:41:08f0.jpg\n",
      "faces/t00:31:55f0.jpg\n",
      "faces/t00:28:47f1.jpg\n",
      "faces/t00:20:53f0.jpg\n",
      "faces/t00:23:53f0.jpg\n",
      "faces/t00:03:16f0.jpg\n",
      "faces/t00:28:35f0.jpg\n",
      "faces/t00:40:48f0.jpg\n",
      "faces/t00:40:40f0.jpg\n",
      "faces/t00:17:53f0.jpg\n",
      "faces/t00:05:38f0.jpg\n",
      "faces/t00:47:34f1.jpg\n",
      "faces/t00:04:22f1.jpg\n",
      "faces/t00:17:41f0.jpg\n",
      "faces/t00:34:04f0.jpg\n",
      "faces/t00:39:36f1.jpg\n",
      "faces/t00:25:51f0.jpg\n",
      "faces/t00:04:36f0.jpg\n",
      "clustering ...\n",
      "#images : #clusters\n",
      "2 : 18\n",
      "3 : 9\n",
      "4 : 3\n",
      "5 : 5\n",
      "6 : 1\n",
      "8 : 3\n",
      "10 : 3\n",
      "13 : 2\n",
      "14 : 1\n",
      "16 : 1\n",
      "23 : 1\n",
      "24 : 2\n",
      "32 : 1\n",
      "70 : 1\n",
      "72 : 1\n",
      "95 : 1\n",
      "106 : 1\n",
      "#images in clusters total:  662\n",
      "cluster dir: faces/imagecluster/clusters\n",
      "plot array (uint8) size: 821.70703125 MiB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main.main('faces/',sim=0.65,vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree SAA_clip_key_frames/imagecluster/clusters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scenes(vid_path, threshold):\n",
    "    \"\"\"Groups shots into scenes\"\"\"\n",
    "    print('Finding shot boundaries...')\n",
    "    shot_bounds = shot_boundaries(vid_path)\n",
    "    print('Extracting key frames...')\n",
    "    key_frames, kf_timestamps = get_key_frames(shot_bounds,vid_path)\n",
    "    #print(key_frames)\n",
    "    scene_count = 0\n",
    "    n_shots = len(key_frames)\n",
    "    scenes = [0] #What scene is each shot - length = no. of shots [Maps shots to scenes]\n",
    "    key_shots = [0] #Key shot for each scene [Maps scenes to their key shots]\n",
    "    print('Classifying shots into scenes...')\n",
    "    for i in tqdm(range(1, n_shots)): #For each shot\n",
    "        curr_shot = key_frames[i]\n",
    "        found = False\n",
    "        for key_shot in key_shots[-1:-16:-1]: #Iterate through key_shots of last few scenes - param\n",
    "            if (similarity(key_frames[key_shot],curr_shot) > threshold):\n",
    "                found = True\n",
    "                scenes.append(scenes[key_shot]) #Mark the shot as belonging to this scene\n",
    "                break\n",
    "        if (found == False): #End of scenes => No matching scene is found\n",
    "            scene_count += 1 \n",
    "            scenes.append(scene_count) #This shot belongs to the new scene\n",
    "            key_shots.append(i) #Mark this shot as key shot of the new scene\n",
    "    return (scenes, key_shots, scene_count, kf_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = find_scenes(\"../../2006-01-02_0000_US_00001057_V11_M2_VHS10_H4_JA.mp4\", 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ping_telegram('Finding scenes done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling data as a binary stream\n",
    "file = open('dump_binary','wb')\n",
    "pickle.dump(output, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pickle\n",
    "infile = open('dump_binary','rb')\n",
    "pp = pickle.load(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
